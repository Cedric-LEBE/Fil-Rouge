{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les biblioth√®ques n√©cessaires\n",
    "import pandas as pd  # Pour la manipulation des donn√©es\n",
    "import numpy as np  # Pour les op√©rations num√©riques\n",
    "import matplotlib.pyplot as plt  # Pour la visualisation des donn√©es\n",
    "import seaborn as sns  # Pour des visualisations statistiques avanc√©es\n",
    "import os\n",
    "# Configurer les options de visualisation\n",
    "sns.set(style=\"whitegrid\")  # D√©finir le style par d√©faut pour seaborn\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)  # D√©finir la taille par d√©faut des figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ DATASETS TRAIN\n",
      "Table : df_Customers.csv, Dimensions : (89316, 4)\n",
      "Table : df_Products.csv, Dimensions : (89316, 6)\n",
      "Table : df_Payments.csv, Dimensions : (89316, 5)\n",
      "Table : df_Orders.csv, Dimensions : (89316, 7)\n",
      "Table : df_OrderItems.csv, Dimensions : (89316, 5)\n",
      "\n",
      "üìÇ DATASETS TEST\n",
      "Table : df_Customers.csv, Dimensions : (38279, 4)\n",
      "Table : df_Products.csv, Dimensions : (38279, 6)\n",
      "Table : df_Payments.csv, Dimensions : (38279, 5)\n",
      "Table : df_Orders.csv, Dimensions : (38279, 4)\n",
      "Table : df_OrderItems.csv, Dimensions : (38279, 5)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# -------- TRAIN --------\n",
    "tr_dir = './data/train'\n",
    "\n",
    "files_train = [\n",
    "    f for f in os.listdir(tr_dir)\n",
    "    if os.path.isfile(os.path.join(tr_dir, f))\n",
    "]\n",
    "\n",
    "tr_dataframes = {}\n",
    "for file in files_train:\n",
    "    file_path = os.path.join(tr_dir, file)\n",
    "    if file.endswith('.csv'):\n",
    "        tr_dataframes[file] = pd.read_csv(file_path)\n",
    "\n",
    "print(\"\\nüìÇ DATASETS TRAIN\")\n",
    "for name, df in tr_dataframes.items():\n",
    "    print(f\"Table : {name}, Dimensions : {df.shape}\")\n",
    "\n",
    "\n",
    "# -------- TEST --------\n",
    "ts_dir = './data/test'\n",
    "\n",
    "files_test = [\n",
    "    f for f in os.listdir(ts_dir)\n",
    "    if os.path.isfile(os.path.join(ts_dir, f))\n",
    "]\n",
    "\n",
    "ts_dataframes = {}\n",
    "for file in files_test:\n",
    "    file_path = os.path.join(ts_dir, file)\n",
    "    if file.endswith('.csv'):\n",
    "        ts_dataframes[file] = pd.read_csv(file_path)\n",
    "\n",
    "print(\"\\nüìÇ DATASETS TEST\")\n",
    "for name, df in ts_dataframes.items():\n",
    "    print(f\"Table : {name}, Dimensions : {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Structure du dataset 'df_Customers.csv':\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 89316 entries, 0 to 89315\n",
      "Data columns (total 4 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   customer_id               89316 non-null  object\n",
      " 1   customer_zip_code_prefix  89316 non-null  int64 \n",
      " 2   customer_city             89316 non-null  object\n",
      " 3   customer_state            89316 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 2.7+ MB\n",
      "None\n",
      "\n",
      "Aper√ßu des premi√®res lignes:\n",
      "    customer_id  customer_zip_code_prefix       customer_city customer_state\n",
      "0  hCT0x9JiGXBQ                     58125     varzea paulista             SP\n",
      "1  PxA7fv9spyhx                      3112  armacao dos buzios             RJ\n",
      "2  g3nXeJkGI0Qw                      4119             jandira             SP\n",
      "3  EOEsCQ6QlpIg                     18212          uberlandia             MG\n",
      "4  mVz5LO2Vd6cL                     88868            ilhabela             SP\n",
      "\n",
      "Statistiques descriptives:\n",
      "         customer_id  customer_zip_code_prefix customer_city customer_state\n",
      "count          89316              89316.000000         89316          89316\n",
      "unique         89316                       NaN          3735             27\n",
      "top     hCT0x9JiGXBQ                       NaN     sao paulo             SP\n",
      "freq               1                       NaN         14352          37879\n",
      "mean             NaN              40499.471080           NaN            NaN\n",
      "std              NaN              31194.386361           NaN            NaN\n",
      "min              NaN               1003.000000           NaN            NaN\n",
      "25%              NaN               9785.000000           NaN            NaN\n",
      "50%              NaN              35480.000000           NaN            NaN\n",
      "75%              NaN              70040.000000           NaN            NaN\n",
      "max              NaN              99990.000000           NaN            NaN\n",
      "\n",
      "Structure du dataset 'df_Products.csv':\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 89316 entries, 0 to 89315\n",
      "Data columns (total 6 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   product_id             89316 non-null  object \n",
      " 1   product_category_name  89008 non-null  object \n",
      " 2   product_weight_g       89301 non-null  float64\n",
      " 3   product_length_cm      89301 non-null  float64\n",
      " 4   product_height_cm      89301 non-null  float64\n",
      " 5   product_width_cm       89301 non-null  float64\n",
      "dtypes: float64(4), object(2)\n",
      "memory usage: 4.1+ MB\n",
      "None\n",
      "\n",
      "Aper√ßu des premi√®res lignes:\n",
      "     product_id     product_category_name  product_weight_g  \\\n",
      "0  90K0C1fIyQUf                      toys             491.0   \n",
      "1  qejhpMGGVcsl             watches_gifts             440.0   \n",
      "2  qUS5d2pEAyxJ  costruction_tools_garden            2200.0   \n",
      "3  639iGvMyv0De                      toys            1450.0   \n",
      "4  1lycYGcsic2F                      toys             300.0   \n",
      "\n",
      "   product_length_cm  product_height_cm  product_width_cm  \n",
      "0               19.0               12.0              16.0  \n",
      "1               18.0               14.0              17.0  \n",
      "2               16.0               16.0              16.0  \n",
      "3               68.0                3.0              48.0  \n",
      "4               17.0                4.0              12.0  \n",
      "\n",
      "Statistiques descriptives:\n",
      "          product_id product_category_name  product_weight_g  \\\n",
      "count          89316                 89008      89301.000000   \n",
      "unique         27451                    70               NaN   \n",
      "top     0vbEvli2JYJu                  toys               NaN   \n",
      "freq             405                 67027               NaN   \n",
      "mean             NaN                   NaN       2087.068129   \n",
      "std              NaN                   NaN       3747.039215   \n",
      "min              NaN                   NaN          0.000000   \n",
      "25%              NaN                   NaN        300.000000   \n",
      "50%              NaN                   NaN        700.000000   \n",
      "75%              NaN                   NaN       1800.000000   \n",
      "max              NaN                   NaN      40425.000000   \n",
      "\n",
      "        product_length_cm  product_height_cm  product_width_cm  \n",
      "count        89301.000000       89301.000000       89301.00000  \n",
      "unique                NaN                NaN               NaN  \n",
      "top                   NaN                NaN               NaN  \n",
      "freq                  NaN                NaN               NaN  \n",
      "mean            30.220658          16.559423          23.03421  \n",
      "std             16.110199          13.388514          11.68828  \n",
      "min              7.000000           2.000000           6.00000  \n",
      "25%             18.000000           8.000000          15.00000  \n",
      "50%             25.000000          13.000000          20.00000  \n",
      "75%             38.000000          20.000000          30.00000  \n",
      "max            105.000000         105.000000         118.00000  \n",
      "\n",
      "Structure du dataset 'df_Payments.csv':\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 89316 entries, 0 to 89315\n",
      "Data columns (total 5 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   order_id              89316 non-null  object \n",
      " 1   payment_sequential    89316 non-null  int64  \n",
      " 2   payment_type          89316 non-null  object \n",
      " 3   payment_installments  89316 non-null  int64  \n",
      " 4   payment_value         89316 non-null  float64\n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 3.4+ MB\n",
      "None\n",
      "\n",
      "Aper√ßu des premi√®res lignes:\n",
      "       order_id  payment_sequential payment_type  payment_installments  \\\n",
      "0  Axfy13Hk4PIk                   1  credit_card                     1   \n",
      "1  v6px92oS8cLG                   1  credit_card                     8   \n",
      "2  Ulpf9skrhjfm                   1  credit_card                     4   \n",
      "3  bwJVWupf2keN                   1  credit_card                     2   \n",
      "4  Dd0QnrMk9Cj5                   1  credit_card                     1   \n",
      "\n",
      "   payment_value  \n",
      "0         259.14  \n",
      "1         382.39  \n",
      "2         249.25  \n",
      "3          27.79  \n",
      "4          76.15  \n",
      "\n",
      "Statistiques descriptives:\n",
      "            order_id  payment_sequential payment_type  payment_installments  \\\n",
      "count          89316        89316.000000        89316          89316.000000   \n",
      "unique         89316                 NaN            4                   NaN   \n",
      "top     Axfy13Hk4PIk                 NaN  credit_card                   NaN   \n",
      "freq               1                 NaN        65814                   NaN   \n",
      "mean             NaN            1.099646          NaN              2.965717   \n",
      "std              NaN            0.772658          NaN              2.796406   \n",
      "min              NaN            1.000000          NaN              0.000000   \n",
      "25%              NaN            1.000000          NaN              1.000000   \n",
      "50%              NaN            1.000000          NaN              2.000000   \n",
      "75%              NaN            1.000000          NaN              4.000000   \n",
      "max              NaN           29.000000          NaN             24.000000   \n",
      "\n",
      "        payment_value  \n",
      "count    89316.000000  \n",
      "unique            NaN  \n",
      "top               NaN  \n",
      "freq              NaN  \n",
      "mean       268.657190  \n",
      "std        344.409566  \n",
      "min          0.000000  \n",
      "25%         84.340000  \n",
      "50%        171.860000  \n",
      "75%        313.530000  \n",
      "max       7274.880000  \n",
      "\n",
      "Structure du dataset 'df_Orders.csv':\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 89316 entries, 0 to 89315\n",
      "Data columns (total 7 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   order_id                       89316 non-null  object\n",
      " 1   customer_id                    89316 non-null  object\n",
      " 2   order_status                   89316 non-null  object\n",
      " 3   order_purchase_timestamp       89316 non-null  object\n",
      " 4   order_approved_at              89307 non-null  object\n",
      " 5   order_delivered_timestamp      87427 non-null  object\n",
      " 6   order_estimated_delivery_date  89316 non-null  object\n",
      "dtypes: object(7)\n",
      "memory usage: 4.8+ MB\n",
      "None\n",
      "\n",
      "Aper√ßu des premi√®res lignes:\n",
      "       order_id   customer_id order_status order_purchase_timestamp  \\\n",
      "0  Axfy13Hk4PIk  hCT0x9JiGXBQ    delivered      2017-10-22 18:57:54   \n",
      "1  v6px92oS8cLG  PxA7fv9spyhx    delivered      2018-06-20 21:40:31   \n",
      "2  Ulpf9skrhjfm  g3nXeJkGI0Qw    delivered      2018-02-16 16:19:31   \n",
      "3  bwJVWupf2keN  EOEsCQ6QlpIg    delivered      2018-08-18 18:04:29   \n",
      "4  Dd0QnrMk9Cj5  mVz5LO2Vd6cL    delivered      2017-12-22 16:44:04   \n",
      "\n",
      "     order_approved_at order_delivered_timestamp order_estimated_delivery_date  \n",
      "0  2017-10-22 19:14:13       2017-10-26 22:19:52                    2017-11-09  \n",
      "1  2018-06-20 22:20:20       2018-07-03 22:51:22                    2018-07-24  \n",
      "2  2018-02-17 16:15:35       2018-02-27 01:29:50                    2018-03-08  \n",
      "3  2018-08-18 18:15:16       2018-08-27 20:03:51                    2018-09-19  \n",
      "4  2017-12-22 17:31:31       2018-01-05 19:22:49                    2018-01-18  \n",
      "\n",
      "Statistiques descriptives:\n",
      "            order_id   customer_id order_status order_purchase_timestamp  \\\n",
      "count          89316         89316        89316                    89316   \n",
      "unique         89316         89316            7                    72775   \n",
      "top     Axfy13Hk4PIk  hCT0x9JiGXBQ    delivered      2017-08-08 20:26:31   \n",
      "freq               1             1        87428                       87   \n",
      "\n",
      "          order_approved_at order_delivered_timestamp  \\\n",
      "count                 89307                     87427   \n",
      "unique                68215                     71143   \n",
      "top     2017-08-08 20:43:31       2017-08-14 12:46:18   \n",
      "freq                     87                        87   \n",
      "\n",
      "       order_estimated_delivery_date  \n",
      "count                          89316  \n",
      "unique                           444  \n",
      "top                       2017-12-20  \n",
      "freq                             500  \n",
      "\n",
      "Structure du dataset 'df_OrderItems.csv':\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 89316 entries, 0 to 89315\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   order_id          89316 non-null  object \n",
      " 1   product_id        89316 non-null  object \n",
      " 2   seller_id         89316 non-null  object \n",
      " 3   price             89316 non-null  float64\n",
      " 4   shipping_charges  89316 non-null  float64\n",
      "dtypes: float64(2), object(3)\n",
      "memory usage: 3.4+ MB\n",
      "None\n",
      "\n",
      "Aper√ßu des premi√®res lignes:\n",
      "       order_id    product_id     seller_id   price  shipping_charges\n",
      "0  Axfy13Hk4PIk  90K0C1fIyQUf  ZWM05J9LcBSF  223.51             84.65\n",
      "1  v6px92oS8cLG  qejhpMGGVcsl  IjlpYfhUbRQs  170.80             23.79\n",
      "2  Ulpf9skrhjfm  qUS5d2pEAyxJ  77p2EYxcM9MD   64.40             17.38\n",
      "3  bwJVWupf2keN  639iGvMyv0De  jWzS0ayv9TGf  264.50             30.72\n",
      "4  Dd0QnrMk9Cj5  1lycYGcsic2F  l1pYW6GBnPMr  779.90             30.66\n",
      "\n",
      "Statistiques descriptives:\n",
      "            order_id    product_id     seller_id         price  \\\n",
      "count          89316         89316         89316  89316.000000   \n",
      "unique         89316         27451          2929           NaN   \n",
      "top     Axfy13Hk4PIk  0vbEvli2JYJu  RKad98cTxhSb           NaN   \n",
      "freq               1           405          1657           NaN   \n",
      "mean             NaN           NaN           NaN    340.900543   \n",
      "std              NaN           NaN           NaN    557.459897   \n",
      "min              NaN           NaN           NaN      0.850000   \n",
      "25%              NaN           NaN           NaN     59.650000   \n",
      "50%              NaN           NaN           NaN    136.900000   \n",
      "75%              NaN           NaN           NaN    399.200000   \n",
      "max              NaN           NaN           NaN   6735.000000   \n",
      "\n",
      "        shipping_charges  \n",
      "count       89316.000000  \n",
      "unique               NaN  \n",
      "top                  NaN  \n",
      "freq                 NaN  \n",
      "mean           44.283210  \n",
      "std            37.672491  \n",
      "min             0.000000  \n",
      "25%            20.110000  \n",
      "50%            35.055000  \n",
      "75%            57.190000  \n",
      "max           409.680000  \n"
     ]
    }
   ],
   "source": [
    "# Examiner la structure des donn√©es pour chaque DataFrame\n",
    "for name, df in tr_dataframes.items():\n",
    "    print(f\"\\nStructure du dataset '{name}':\")\n",
    "    print(df.info())  # Afficher les informations sur les colonnes et les types de donn√©es\n",
    "    print(\"\\nAper√ßu des premi√®res lignes:\")\n",
    "    print(df.head())  # Afficher les premi√®res lignes du DataFrame\n",
    "    print(\"\\nStatistiques descriptives:\")\n",
    "    print(df.describe(include='all'))  # Afficher les statistiques descriptives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Structure du dataset 'df_Customers.csv':\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38279 entries, 0 to 38278\n",
      "Data columns (total 4 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   customer_id               38279 non-null  object\n",
      " 1   customer_zip_code_prefix  38279 non-null  int64 \n",
      " 2   customer_city             38279 non-null  object\n",
      " 3   customer_state            38279 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 1.2+ MB\n",
      "None\n",
      "\n",
      "Aper√ßu des premi√®res lignes:\n",
      "    customer_id  customer_zip_code_prefix        customer_city customer_state\n",
      "0  I74lXDOfoqsp                      6020              goiania             GO\n",
      "1  47TuLHF2s7X5                     23020               viamao             RS\n",
      "2  dQ0dqI8Qwlj8                     75094             campinas             SP\n",
      "3  iQCmWhNkIczb                     89284  santana de parnaiba             SP\n",
      "4  Dp2g6JH8tO5Z                     39810             aripuana             MT\n",
      "\n",
      "Statistiques descriptives:\n",
      "         customer_id  customer_zip_code_prefix customer_city customer_state\n",
      "count          38279              38279.000000         38279          38279\n",
      "unique         38279                       NaN          2804             27\n",
      "top     I74lXDOfoqsp                       NaN     sao paulo             SP\n",
      "freq               1                       NaN          6160          16188\n",
      "mean             NaN              40446.840200           NaN            NaN\n",
      "std              NaN              31125.594129           NaN            NaN\n",
      "min              NaN               1003.000000           NaN            NaN\n",
      "25%              NaN               9792.000000           NaN            NaN\n",
      "50%              NaN              35340.000000           NaN            NaN\n",
      "75%              NaN              69068.000000           NaN            NaN\n",
      "max              NaN              99980.000000           NaN            NaN\n",
      "\n",
      "Structure du dataset 'df_Products.csv':\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38279 entries, 0 to 38278\n",
      "Data columns (total 6 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   product_id             38279 non-null  object \n",
      " 1   product_category_name  38111 non-null  object \n",
      " 2   product_weight_g       38269 non-null  float64\n",
      " 3   product_length_cm      38269 non-null  float64\n",
      " 4   product_height_cm      38269 non-null  float64\n",
      " 5   product_width_cm       38269 non-null  float64\n",
      "dtypes: float64(4), object(2)\n",
      "memory usage: 1.8+ MB\n",
      "None\n",
      "\n",
      "Aper√ßu des premi√®res lignes:\n",
      "     product_id product_category_name  product_weight_g  product_length_cm  \\\n",
      "0  1slxdgbgWFax                  toys              50.0               16.0   \n",
      "1  77PgsiElQLeB           electronics             200.0               21.0   \n",
      "2  QVlD26X1y7NI       furniture_decor            1000.0              100.0   \n",
      "3  yWlFGkKYfrpa                  toys            8950.0               40.0   \n",
      "4  h6MCbrwh5kiC                  toys            2301.0               32.0   \n",
      "\n",
      "   product_height_cm  product_width_cm  \n",
      "0                5.0              11.0  \n",
      "1                7.0              14.0  \n",
      "2                5.0              20.0  \n",
      "3               30.0              40.0  \n",
      "4               35.0              34.0  \n",
      "\n",
      "Statistiques descriptives:\n",
      "          product_id product_category_name  product_weight_g  \\\n",
      "count          38279                 38111      38269.000000   \n",
      "unique         16604                    66               NaN   \n",
      "top     UgkSjxoiV9Ev                  toys               NaN   \n",
      "freq             164                 28697               NaN   \n",
      "mean             NaN                   NaN       2118.472576   \n",
      "std              NaN                   NaN       3827.606405   \n",
      "min              NaN                   NaN          0.000000   \n",
      "25%              NaN                   NaN        300.000000   \n",
      "50%              NaN                   NaN        700.000000   \n",
      "75%              NaN                   NaN       1800.000000   \n",
      "max              NaN                   NaN      30000.000000   \n",
      "\n",
      "        product_length_cm  product_height_cm  product_width_cm  \n",
      "count        38269.000000       38269.000000      38269.000000  \n",
      "unique                NaN                NaN               NaN  \n",
      "top                   NaN                NaN               NaN  \n",
      "freq                  NaN                NaN               NaN  \n",
      "mean            30.316366          16.504717         23.154146  \n",
      "std             16.258049          13.370506         11.869977  \n",
      "min              7.000000           2.000000          8.000000  \n",
      "25%             18.000000           8.000000         15.000000  \n",
      "50%             25.000000          13.000000         20.000000  \n",
      "75%             38.000000          20.000000         30.000000  \n",
      "max            105.000000         105.000000        118.000000  \n",
      "\n",
      "Structure du dataset 'df_Payments.csv':\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38279 entries, 0 to 38278\n",
      "Data columns (total 5 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   order_id              38279 non-null  object \n",
      " 1   payment_sequential    38279 non-null  int64  \n",
      " 2   payment_type          38279 non-null  object \n",
      " 3   payment_installments  38279 non-null  int64  \n",
      " 4   payment_value         38279 non-null  float64\n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 1.5+ MB\n",
      "None\n",
      "\n",
      "Aper√ßu des premi√®res lignes:\n",
      "       order_id  payment_sequential payment_type  payment_installments  \\\n",
      "0  u6rPMRAYIGig                   1  credit_card                     2   \n",
      "1  ohY8f4FEbX19                   1  credit_card                     1   \n",
      "2  I28liQek73i2                   1       wallet                     1   \n",
      "3  bBG1T89mlY8W                   1  credit_card                     3   \n",
      "4  CYxJJSQS8Lbo                   1       wallet                     1   \n",
      "\n",
      "   payment_value  \n",
      "0         155.77  \n",
      "1           4.07  \n",
      "2         381.59  \n",
      "3          14.76  \n",
      "4         284.09  \n",
      "\n",
      "Statistiques descriptives:\n",
      "            order_id  payment_sequential payment_type  payment_installments  \\\n",
      "count          38279        38279.000000        38279          38279.000000   \n",
      "unique         38279                 NaN            4                   NaN   \n",
      "top     u6rPMRAYIGig                 NaN  credit_card                   NaN   \n",
      "freq               1                 NaN        28265                   NaN   \n",
      "mean             NaN            1.096606          NaN              2.982105   \n",
      "std              NaN            0.742181          NaN              2.836529   \n",
      "min              NaN            1.000000          NaN              1.000000   \n",
      "25%              NaN            1.000000          NaN              1.000000   \n",
      "50%              NaN            1.000000          NaN              2.000000   \n",
      "75%              NaN            1.000000          NaN              4.000000   \n",
      "max              NaN           27.000000          NaN             24.000000   \n",
      "\n",
      "        payment_value  \n",
      "count    38279.000000  \n",
      "unique            NaN  \n",
      "top               NaN  \n",
      "freq              NaN  \n",
      "mean       267.698041  \n",
      "std        366.310037  \n",
      "min          0.030000  \n",
      "25%         82.175000  \n",
      "50%        171.930000  \n",
      "75%        309.205000  \n",
      "max      13664.080000  \n",
      "\n",
      "Structure du dataset 'df_Orders.csv':\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38279 entries, 0 to 38278\n",
      "Data columns (total 4 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   order_id                  38279 non-null  object\n",
      " 1   customer_id               38279 non-null  object\n",
      " 2   order_purchase_timestamp  38279 non-null  object\n",
      " 3   order_approved_at         38272 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 1.2+ MB\n",
      "None\n",
      "\n",
      "Aper√ßu des premi√®res lignes:\n",
      "       order_id   customer_id order_purchase_timestamp    order_approved_at\n",
      "0  u6rPMRAYIGig  I74lXDOfoqsp      2017-11-18 12:29:57  2017-11-18 12:46:08\n",
      "1  ohY8f4FEbX19  47TuLHF2s7X5      2018-06-02 17:13:12  2018-06-02 20:12:23\n",
      "2  I28liQek73i2  dQ0dqI8Qwlj8      2018-01-08 11:01:30  2018-01-09 07:24:03\n",
      "3  bBG1T89mlY8W  iQCmWhNkIczb      2017-03-10 10:24:46  2017-03-10 10:24:46\n",
      "4  CYxJJSQS8Lbo  Dp2g6JH8tO5Z      2017-12-02 10:04:07  2017-12-05 04:13:30\n",
      "\n",
      "Statistiques descriptives:\n",
      "            order_id   customer_id order_purchase_timestamp  \\\n",
      "count          38279         38279                    38279   \n",
      "unique         38279         38279                    34255   \n",
      "top     u6rPMRAYIGig  I74lXDOfoqsp      2017-08-08 20:26:31   \n",
      "freq               1             1                       39   \n",
      "\n",
      "          order_approved_at  \n",
      "count                 38272  \n",
      "unique                33278  \n",
      "top     2017-08-08 20:43:31  \n",
      "freq                     39  \n",
      "\n",
      "Structure du dataset 'df_OrderItems.csv':\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38279 entries, 0 to 38278\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   order_id          38279 non-null  object \n",
      " 1   product_id        38279 non-null  object \n",
      " 2   seller_id         38279 non-null  object \n",
      " 3   price             38279 non-null  float64\n",
      " 4   shipping_charges  38279 non-null  float64\n",
      "dtypes: float64(2), object(3)\n",
      "memory usage: 1.5+ MB\n",
      "None\n",
      "\n",
      "Aper√ßu des premi√®res lignes:\n",
      "       order_id    product_id     seller_id    price  shipping_charges\n",
      "0  u6rPMRAYIGig  1slxdgbgWFax  3jwvL6ihC45G    24.10             20.90\n",
      "1  ohY8f4FEbX19  77PgsiElQLeB  GlLj704QXlDB    42.89             12.28\n",
      "2  I28liQek73i2  QVlD26X1y7NI  V3iKL8r9W9NR    50.21             67.11\n",
      "3  bBG1T89mlY8W  yWlFGkKYfrpa  RNBdBKsXebna    89.10             62.05\n",
      "4  CYxJJSQS8Lbo  h6MCbrwh5kiC  5Ja2lH0N2OZt  2139.99              9.41\n",
      "\n",
      "Statistiques descriptives:\n",
      "            order_id    product_id     seller_id         price  \\\n",
      "count          38279         38279         38279  38279.000000   \n",
      "unique         38279         16604          2476           NaN   \n",
      "top     u6rPMRAYIGig  UgkSjxoiV9Ev  yGbPyLPc8PmT           NaN   \n",
      "freq               1           164           719           NaN   \n",
      "mean             NaN           NaN           NaN    342.499934   \n",
      "std              NaN           NaN           NaN    560.285949   \n",
      "min              NaN           NaN           NaN      0.850000   \n",
      "25%              NaN           NaN           NaN     59.880000   \n",
      "50%              NaN           NaN           NaN    136.900000   \n",
      "75%              NaN           NaN           NaN    399.200000   \n",
      "max              NaN           NaN           NaN   6729.000000   \n",
      "\n",
      "        shipping_charges  \n",
      "count       38279.000000  \n",
      "unique               NaN  \n",
      "top                  NaN  \n",
      "freq                 NaN  \n",
      "mean           44.194071  \n",
      "std            37.738984  \n",
      "min             0.000000  \n",
      "25%            19.930000  \n",
      "50%            34.600000  \n",
      "75%            57.120000  \n",
      "max           409.680000  \n"
     ]
    }
   ],
   "source": [
    "# Examiner la structure des donn√©es pour chaque DataFrame\n",
    "for name, df in ts_dataframes.items():\n",
    "    print(f\"\\nStructure du dataset '{name}':\")\n",
    "    print(df.info())  # Afficher les informations sur les colonnes et les types de donn√©es\n",
    "    print(\"\\nAper√ßu des premi√®res lignes:\")\n",
    "    print(df.head())  # Afficher les premi√®res lignes du DataFrame\n",
    "    print(\"\\nStatistiques descriptives:\")\n",
    "    print(df.describe(include='all'))  # Afficher les statistiques descriptives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_orders = tr_dataframes['df_Orders.csv']\n",
    "tr_custs  = tr_dataframes['df_Customers.csv']\n",
    "tr_items  = tr_dataframes['df_OrderItems.csv']\n",
    "tr_pays   = tr_dataframes['df_Payments.csv']\n",
    "tr_prods  = tr_dataframes['df_Products.csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_orders = ts_dataframes['df_Orders.csv']\n",
    "ts_custs  = ts_dataframes['df_Customers.csv']\n",
    "ts_items  = ts_dataframes['df_OrderItems.csv']\n",
    "ts_pays   = ts_dataframes['df_Payments.csv']\n",
    "ts_prods  = ts_dataframes['df_Products.csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_status</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_delivered_timestamp</th>\n",
       "      <th>order_estimated_delivery_date</th>\n",
       "      <th>customer_zip_code_prefix</th>\n",
       "      <th>customer_city</th>\n",
       "      <th>customer_state</th>\n",
       "      <th>...</th>\n",
       "      <th>shipping_charges</th>\n",
       "      <th>payment_sequential</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>payment_installments</th>\n",
       "      <th>payment_value</th>\n",
       "      <th>product_category_name</th>\n",
       "      <th>product_weight_g</th>\n",
       "      <th>product_length_cm</th>\n",
       "      <th>product_height_cm</th>\n",
       "      <th>product_width_cm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Axfy13Hk4PIk</td>\n",
       "      <td>hCT0x9JiGXBQ</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-10-22 18:57:54</td>\n",
       "      <td>2017-10-22 19:14:13</td>\n",
       "      <td>2017-10-26 22:19:52</td>\n",
       "      <td>2017-11-09</td>\n",
       "      <td>58125</td>\n",
       "      <td>varzea paulista</td>\n",
       "      <td>SP</td>\n",
       "      <td>...</td>\n",
       "      <td>84.65</td>\n",
       "      <td>1</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>1</td>\n",
       "      <td>259.14</td>\n",
       "      <td>toys</td>\n",
       "      <td>491.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>v6px92oS8cLG</td>\n",
       "      <td>PxA7fv9spyhx</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-06-20 21:40:31</td>\n",
       "      <td>2018-06-20 22:20:20</td>\n",
       "      <td>2018-07-03 22:51:22</td>\n",
       "      <td>2018-07-24</td>\n",
       "      <td>3112</td>\n",
       "      <td>armacao dos buzios</td>\n",
       "      <td>RJ</td>\n",
       "      <td>...</td>\n",
       "      <td>23.79</td>\n",
       "      <td>1</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>8</td>\n",
       "      <td>382.39</td>\n",
       "      <td>watches_gifts</td>\n",
       "      <td>440.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ulpf9skrhjfm</td>\n",
       "      <td>g3nXeJkGI0Qw</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-02-16 16:19:31</td>\n",
       "      <td>2018-02-17 16:15:35</td>\n",
       "      <td>2018-02-27 01:29:50</td>\n",
       "      <td>2018-03-08</td>\n",
       "      <td>4119</td>\n",
       "      <td>jandira</td>\n",
       "      <td>SP</td>\n",
       "      <td>...</td>\n",
       "      <td>17.38</td>\n",
       "      <td>1</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>4</td>\n",
       "      <td>249.25</td>\n",
       "      <td>costruction_tools_garden</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bwJVWupf2keN</td>\n",
       "      <td>EOEsCQ6QlpIg</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-08-18 18:04:29</td>\n",
       "      <td>2018-08-18 18:15:16</td>\n",
       "      <td>2018-08-27 20:03:51</td>\n",
       "      <td>2018-09-19</td>\n",
       "      <td>18212</td>\n",
       "      <td>uberlandia</td>\n",
       "      <td>MG</td>\n",
       "      <td>...</td>\n",
       "      <td>30.72</td>\n",
       "      <td>1</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>2</td>\n",
       "      <td>27.79</td>\n",
       "      <td>toys</td>\n",
       "      <td>1450.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dd0QnrMk9Cj5</td>\n",
       "      <td>mVz5LO2Vd6cL</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-12-22 16:44:04</td>\n",
       "      <td>2017-12-22 17:31:31</td>\n",
       "      <td>2018-01-05 19:22:49</td>\n",
       "      <td>2018-01-18</td>\n",
       "      <td>88868</td>\n",
       "      <td>ilhabela</td>\n",
       "      <td>SP</td>\n",
       "      <td>...</td>\n",
       "      <td>30.66</td>\n",
       "      <td>1</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>1</td>\n",
       "      <td>76.15</td>\n",
       "      <td>toys</td>\n",
       "      <td>300.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       order_id   customer_id order_status order_purchase_timestamp  \\\n",
       "0  Axfy13Hk4PIk  hCT0x9JiGXBQ    delivered      2017-10-22 18:57:54   \n",
       "1  v6px92oS8cLG  PxA7fv9spyhx    delivered      2018-06-20 21:40:31   \n",
       "2  Ulpf9skrhjfm  g3nXeJkGI0Qw    delivered      2018-02-16 16:19:31   \n",
       "3  bwJVWupf2keN  EOEsCQ6QlpIg    delivered      2018-08-18 18:04:29   \n",
       "4  Dd0QnrMk9Cj5  mVz5LO2Vd6cL    delivered      2017-12-22 16:44:04   \n",
       "\n",
       "     order_approved_at order_delivered_timestamp  \\\n",
       "0  2017-10-22 19:14:13       2017-10-26 22:19:52   \n",
       "1  2018-06-20 22:20:20       2018-07-03 22:51:22   \n",
       "2  2018-02-17 16:15:35       2018-02-27 01:29:50   \n",
       "3  2018-08-18 18:15:16       2018-08-27 20:03:51   \n",
       "4  2017-12-22 17:31:31       2018-01-05 19:22:49   \n",
       "\n",
       "  order_estimated_delivery_date  customer_zip_code_prefix       customer_city  \\\n",
       "0                    2017-11-09                     58125     varzea paulista   \n",
       "1                    2018-07-24                      3112  armacao dos buzios   \n",
       "2                    2018-03-08                      4119             jandira   \n",
       "3                    2018-09-19                     18212          uberlandia   \n",
       "4                    2018-01-18                     88868            ilhabela   \n",
       "\n",
       "  customer_state  ... shipping_charges payment_sequential  payment_type  \\\n",
       "0             SP  ...            84.65                  1   credit_card   \n",
       "1             RJ  ...            23.79                  1   credit_card   \n",
       "2             SP  ...            17.38                  1   credit_card   \n",
       "3             MG  ...            30.72                  1   credit_card   \n",
       "4             SP  ...            30.66                  1   credit_card   \n",
       "\n",
       "   payment_installments  payment_value     product_category_name  \\\n",
       "0                     1         259.14                      toys   \n",
       "1                     8         382.39             watches_gifts   \n",
       "2                     4         249.25  costruction_tools_garden   \n",
       "3                     2          27.79                      toys   \n",
       "4                     1          76.15                      toys   \n",
       "\n",
       "   product_weight_g  product_length_cm product_height_cm  product_width_cm  \n",
       "0             491.0               19.0              12.0              16.0  \n",
       "1             440.0               18.0              14.0              17.0  \n",
       "2            2200.0               16.0              16.0              16.0  \n",
       "3            1450.0               68.0               3.0              48.0  \n",
       "4             300.0               17.0               4.0              12.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_prods = tr_prods.drop_duplicates() #--> drop duplicates in product\n",
    "# Merge cust and order on customer_id\n",
    "tr_data = tr_orders.merge(tr_custs, on=\"customer_id\", how=\"left\")\n",
    "# Merge with items on order_id\n",
    "tr_data = tr_data.merge(tr_items, on=\"order_id\", how=\"left\")\n",
    "# Merge with pays on order_id\n",
    "tr_data = tr_data.merge(tr_pays, on=\"order_id\", how=\"left\")\n",
    "# Merge with prods on product_id\n",
    "tr_data = tr_data.merge(tr_prods, on=\"product_id\", how=\"left\")\n",
    "tr_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>customer_zip_code_prefix</th>\n",
       "      <th>customer_city</th>\n",
       "      <th>customer_state</th>\n",
       "      <th>product_id</th>\n",
       "      <th>seller_id</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping_charges</th>\n",
       "      <th>payment_sequential</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>payment_installments</th>\n",
       "      <th>payment_value</th>\n",
       "      <th>product_category_name</th>\n",
       "      <th>product_weight_g</th>\n",
       "      <th>product_length_cm</th>\n",
       "      <th>product_height_cm</th>\n",
       "      <th>product_width_cm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u6rPMRAYIGig</td>\n",
       "      <td>I74lXDOfoqsp</td>\n",
       "      <td>2017-11-18 12:29:57</td>\n",
       "      <td>2017-11-18 12:46:08</td>\n",
       "      <td>6020</td>\n",
       "      <td>goiania</td>\n",
       "      <td>GO</td>\n",
       "      <td>1slxdgbgWFax</td>\n",
       "      <td>3jwvL6ihC45G</td>\n",
       "      <td>24.10</td>\n",
       "      <td>20.90</td>\n",
       "      <td>1</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>2</td>\n",
       "      <td>155.77</td>\n",
       "      <td>toys</td>\n",
       "      <td>50.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ohY8f4FEbX19</td>\n",
       "      <td>47TuLHF2s7X5</td>\n",
       "      <td>2018-06-02 17:13:12</td>\n",
       "      <td>2018-06-02 20:12:23</td>\n",
       "      <td>23020</td>\n",
       "      <td>viamao</td>\n",
       "      <td>RS</td>\n",
       "      <td>77PgsiElQLeB</td>\n",
       "      <td>GlLj704QXlDB</td>\n",
       "      <td>42.89</td>\n",
       "      <td>12.28</td>\n",
       "      <td>1</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>1</td>\n",
       "      <td>4.07</td>\n",
       "      <td>electronics</td>\n",
       "      <td>200.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I28liQek73i2</td>\n",
       "      <td>dQ0dqI8Qwlj8</td>\n",
       "      <td>2018-01-08 11:01:30</td>\n",
       "      <td>2018-01-09 07:24:03</td>\n",
       "      <td>75094</td>\n",
       "      <td>campinas</td>\n",
       "      <td>SP</td>\n",
       "      <td>QVlD26X1y7NI</td>\n",
       "      <td>V3iKL8r9W9NR</td>\n",
       "      <td>50.21</td>\n",
       "      <td>67.11</td>\n",
       "      <td>1</td>\n",
       "      <td>wallet</td>\n",
       "      <td>1</td>\n",
       "      <td>381.59</td>\n",
       "      <td>furniture_decor</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bBG1T89mlY8W</td>\n",
       "      <td>iQCmWhNkIczb</td>\n",
       "      <td>2017-03-10 10:24:46</td>\n",
       "      <td>2017-03-10 10:24:46</td>\n",
       "      <td>89284</td>\n",
       "      <td>santana de parnaiba</td>\n",
       "      <td>SP</td>\n",
       "      <td>yWlFGkKYfrpa</td>\n",
       "      <td>RNBdBKsXebna</td>\n",
       "      <td>89.10</td>\n",
       "      <td>62.05</td>\n",
       "      <td>1</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>3</td>\n",
       "      <td>14.76</td>\n",
       "      <td>toys</td>\n",
       "      <td>8950.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CYxJJSQS8Lbo</td>\n",
       "      <td>Dp2g6JH8tO5Z</td>\n",
       "      <td>2017-12-02 10:04:07</td>\n",
       "      <td>2017-12-05 04:13:30</td>\n",
       "      <td>39810</td>\n",
       "      <td>aripuana</td>\n",
       "      <td>MT</td>\n",
       "      <td>h6MCbrwh5kiC</td>\n",
       "      <td>5Ja2lH0N2OZt</td>\n",
       "      <td>2139.99</td>\n",
       "      <td>9.41</td>\n",
       "      <td>1</td>\n",
       "      <td>wallet</td>\n",
       "      <td>1</td>\n",
       "      <td>284.09</td>\n",
       "      <td>toys</td>\n",
       "      <td>2301.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       order_id   customer_id order_purchase_timestamp    order_approved_at  \\\n",
       "0  u6rPMRAYIGig  I74lXDOfoqsp      2017-11-18 12:29:57  2017-11-18 12:46:08   \n",
       "1  ohY8f4FEbX19  47TuLHF2s7X5      2018-06-02 17:13:12  2018-06-02 20:12:23   \n",
       "2  I28liQek73i2  dQ0dqI8Qwlj8      2018-01-08 11:01:30  2018-01-09 07:24:03   \n",
       "3  bBG1T89mlY8W  iQCmWhNkIczb      2017-03-10 10:24:46  2017-03-10 10:24:46   \n",
       "4  CYxJJSQS8Lbo  Dp2g6JH8tO5Z      2017-12-02 10:04:07  2017-12-05 04:13:30   \n",
       "\n",
       "   customer_zip_code_prefix        customer_city customer_state    product_id  \\\n",
       "0                      6020              goiania             GO  1slxdgbgWFax   \n",
       "1                     23020               viamao             RS  77PgsiElQLeB   \n",
       "2                     75094             campinas             SP  QVlD26X1y7NI   \n",
       "3                     89284  santana de parnaiba             SP  yWlFGkKYfrpa   \n",
       "4                     39810             aripuana             MT  h6MCbrwh5kiC   \n",
       "\n",
       "      seller_id    price  shipping_charges  payment_sequential payment_type  \\\n",
       "0  3jwvL6ihC45G    24.10             20.90                   1  credit_card   \n",
       "1  GlLj704QXlDB    42.89             12.28                   1  credit_card   \n",
       "2  V3iKL8r9W9NR    50.21             67.11                   1       wallet   \n",
       "3  RNBdBKsXebna    89.10             62.05                   1  credit_card   \n",
       "4  5Ja2lH0N2OZt  2139.99              9.41                   1       wallet   \n",
       "\n",
       "   payment_installments  payment_value product_category_name  \\\n",
       "0                     2         155.77                  toys   \n",
       "1                     1           4.07           electronics   \n",
       "2                     1         381.59       furniture_decor   \n",
       "3                     3          14.76                  toys   \n",
       "4                     1         284.09                  toys   \n",
       "\n",
       "   product_weight_g  product_length_cm  product_height_cm  product_width_cm  \n",
       "0              50.0               16.0                5.0              11.0  \n",
       "1             200.0               21.0                7.0              14.0  \n",
       "2            1000.0              100.0                5.0              20.0  \n",
       "3            8950.0               40.0               30.0              40.0  \n",
       "4            2301.0               32.0               35.0              34.0  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_prods = ts_prods.drop_duplicates() #--> drop duplicates in product\n",
    "# Merge cust and order on customer_id\n",
    "ts_data = ts_orders.merge(ts_custs, on=\"customer_id\", how=\"left\")\n",
    "# Merge with item on order_id\n",
    "ts_data = ts_data.merge(ts_items, on=\"order_id\", how=\"left\")\n",
    "# Merge with pay on order_id\n",
    "ts_data = ts_data.merge(ts_pays, on=\"order_id\", how=\"left\")\n",
    "# Merge with prod on product_id\n",
    "ts_data = ts_data.merge(ts_prods, on=\"product_id\", how=\"left\")\n",
    "ts_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Statistiques descriptives pour le fichier: order_id ---\n",
      "count            89316\n",
      "unique           89316\n",
      "top       Axfy13Hk4PIk\n",
      "freq                 1\n",
      "Name: order_id, dtype: object\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "--- Statistiques descriptives pour le fichier: customer_id ---\n",
      "count            89316\n",
      "unique           89316\n",
      "top       hCT0x9JiGXBQ\n",
      "freq                 1\n",
      "Name: customer_id, dtype: object\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "--- Statistiques descriptives pour le fichier: order_status ---\n",
      "count         89316\n",
      "unique            7\n",
      "top       delivered\n",
      "freq          87428\n",
      "Name: order_status, dtype: object\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "--- Statistiques descriptives pour le fichier: order_purchase_timestamp ---\n",
      "count                   89316\n",
      "unique                  72775\n",
      "top       2017-08-08 20:26:31\n",
      "freq                       87\n",
      "Name: order_purchase_timestamp, dtype: object\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "--- Statistiques descriptives pour le fichier: order_approved_at ---\n",
      "count                   89307\n",
      "unique                  68215\n",
      "top       2017-08-08 20:43:31\n",
      "freq                       87\n",
      "Name: order_approved_at, dtype: object\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "--- Statistiques descriptives pour le fichier: order_delivered_timestamp ---\n",
      "count                   87427\n",
      "unique                  71143\n",
      "top       2017-08-14 12:46:18\n",
      "freq                       87\n",
      "Name: order_delivered_timestamp, dtype: object\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "--- Statistiques descriptives pour le fichier: order_estimated_delivery_date ---\n",
      "count          89316\n",
      "unique           444\n",
      "top       2017-12-20\n",
      "freq             500\n",
      "Name: order_estimated_delivery_date, dtype: object\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "--- Statistiques descriptives pour le fichier: customer_zip_code_prefix ---\n",
      "count    89316.000000\n",
      "mean     40499.471080\n",
      "std      31194.386361\n",
      "min       1003.000000\n",
      "25%       9785.000000\n",
      "50%      35480.000000\n",
      "75%      70040.000000\n",
      "max      99990.000000\n",
      "Name: customer_zip_code_prefix, dtype: float64\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "--- Statistiques descriptives pour le fichier: customer_city ---\n",
      "count         89316\n",
      "unique         3735\n",
      "top       sao paulo\n",
      "freq          14352\n",
      "Name: customer_city, dtype: object\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "--- Statistiques descriptives pour le fichier: customer_state ---\n",
      "count     89316\n",
      "unique       27\n",
      "top          SP\n",
      "freq      37879\n",
      "Name: customer_state, dtype: object\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "--- Statistiques descriptives pour le fichier: product_id ---\n",
      "count            89316\n",
      "unique           27451\n",
      "top       0vbEvli2JYJu\n",
      "freq               405\n",
      "Name: product_id, dtype: object\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "--- Statistiques descriptives pour le fichier: seller_id ---\n",
      "count            89316\n",
      "unique            2929\n",
      "top       RKad98cTxhSb\n",
      "freq              1657\n",
      "Name: seller_id, dtype: object\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "--- Statistiques descriptives pour le fichier: price ---\n",
      "count    89316.000000\n",
      "mean       340.900543\n",
      "std        557.459897\n",
      "min          0.850000\n",
      "25%         59.650000\n",
      "50%        136.900000\n",
      "75%        399.200000\n",
      "max       6735.000000\n",
      "Name: price, dtype: float64\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "--- Statistiques descriptives pour le fichier: shipping_charges ---\n",
      "count    89316.000000\n",
      "mean        44.283210\n",
      "std         37.672491\n",
      "min          0.000000\n",
      "25%         20.110000\n",
      "50%         35.055000\n",
      "75%         57.190000\n",
      "max        409.680000\n",
      "Name: shipping_charges, dtype: float64\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "--- Statistiques descriptives pour le fichier: payment_sequential ---\n",
      "count    89316.000000\n",
      "mean         1.099646\n",
      "std          0.772658\n",
      "min          1.000000\n",
      "25%          1.000000\n",
      "50%          1.000000\n",
      "75%          1.000000\n",
      "max         29.000000\n",
      "Name: payment_sequential, dtype: float64\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "--- Statistiques descriptives pour le fichier: payment_type ---\n",
      "count           89316\n",
      "unique              4\n",
      "top       credit_card\n",
      "freq            65814\n",
      "Name: payment_type, dtype: object\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "--- Statistiques descriptives pour le fichier: payment_installments ---\n",
      "count    89316.000000\n",
      "mean         2.965717\n",
      "std          2.796406\n",
      "min          0.000000\n",
      "25%          1.000000\n",
      "50%          2.000000\n",
      "75%          4.000000\n",
      "max         24.000000\n",
      "Name: payment_installments, dtype: float64\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "--- Statistiques descriptives pour le fichier: payment_value ---\n",
      "count    89316.000000\n",
      "mean       268.657190\n",
      "std        344.409566\n",
      "min          0.000000\n",
      "25%         84.340000\n",
      "50%        171.860000\n",
      "75%        313.530000\n",
      "max       7274.880000\n",
      "Name: payment_value, dtype: float64\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "--- Statistiques descriptives pour le fichier: product_category_name ---\n",
      "count     89008\n",
      "unique       70\n",
      "top        toys\n",
      "freq      67027\n",
      "Name: product_category_name, dtype: object\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "--- Statistiques descriptives pour le fichier: product_weight_g ---\n",
      "count    89301.000000\n",
      "mean      2087.068129\n",
      "std       3747.039215\n",
      "min          0.000000\n",
      "25%        300.000000\n",
      "50%        700.000000\n",
      "75%       1800.000000\n",
      "max      40425.000000\n",
      "Name: product_weight_g, dtype: float64\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "--- Statistiques descriptives pour le fichier: product_length_cm ---\n",
      "count    89301.000000\n",
      "mean        30.220658\n",
      "std         16.110199\n",
      "min          7.000000\n",
      "25%         18.000000\n",
      "50%         25.000000\n",
      "75%         38.000000\n",
      "max        105.000000\n",
      "Name: product_length_cm, dtype: float64\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "--- Statistiques descriptives pour le fichier: product_height_cm ---\n",
      "count    89301.000000\n",
      "mean        16.559423\n",
      "std         13.388514\n",
      "min          2.000000\n",
      "25%          8.000000\n",
      "50%         13.000000\n",
      "75%         20.000000\n",
      "max        105.000000\n",
      "Name: product_height_cm, dtype: float64\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "--- Statistiques descriptives pour le fichier: product_width_cm ---\n",
      "count    89301.00000\n",
      "mean        23.03421\n",
      "std         11.68828\n",
      "min          6.00000\n",
      "25%         15.00000\n",
      "50%         20.00000\n",
      "75%         30.00000\n",
      "max        118.00000\n",
      "Name: product_width_cm, dtype: float64\n",
      "\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "# Analyse Statistique \n",
    "\n",
    "# Utiliser la m√©thode describe() pour obtenir des statistiques descriptives sur les colonnes num√©riques\n",
    "for name, df in tr_data.items():\n",
    "    print(f\"\\n--- Statistiques descriptives pour le fichier: {name} ---\")\n",
    "    print(df.describe())  # Afficher les statistiques descriptives\n",
    "    print(\"\\n-----------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Statistiques descriptives pour le fichier: order_id ---\n",
      "count            38279\n",
      "unique           38279\n",
      "top       u6rPMRAYIGig\n",
      "freq                 1\n",
      "Name: order_id, dtype: object\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "--- Statistiques descriptives pour le fichier: customer_id ---\n",
      "count            38279\n",
      "unique           38279\n",
      "top       I74lXDOfoqsp\n",
      "freq                 1\n",
      "Name: customer_id, dtype: object\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "--- Statistiques descriptives pour le fichier: order_purchase_timestamp ---\n",
      "count                   38279\n",
      "unique                  34255\n",
      "top       2017-08-08 20:26:31\n",
      "freq                       39\n",
      "Name: order_purchase_timestamp, dtype: object\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "--- Statistiques descriptives pour le fichier: order_approved_at ---\n",
      "count                   38272\n",
      "unique                  33278\n",
      "top       2017-08-08 20:43:31\n",
      "freq                       39\n",
      "Name: order_approved_at, dtype: object\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "--- Statistiques descriptives pour le fichier: customer_zip_code_prefix ---\n",
      "count    38279.000000\n",
      "mean     40446.840200\n",
      "std      31125.594129\n",
      "min       1003.000000\n",
      "25%       9792.000000\n",
      "50%      35340.000000\n",
      "75%      69068.000000\n",
      "max      99980.000000\n",
      "Name: customer_zip_code_prefix, dtype: float64\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "--- Statistiques descriptives pour le fichier: customer_city ---\n",
      "count         38279\n",
      "unique         2804\n",
      "top       sao paulo\n",
      "freq           6160\n",
      "Name: customer_city, dtype: object\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "--- Statistiques descriptives pour le fichier: customer_state ---\n",
      "count     38279\n",
      "unique       27\n",
      "top          SP\n",
      "freq      16188\n",
      "Name: customer_state, dtype: object\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "--- Statistiques descriptives pour le fichier: product_id ---\n",
      "count            38279\n",
      "unique           16604\n",
      "top       UgkSjxoiV9Ev\n",
      "freq               164\n",
      "Name: product_id, dtype: object\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "--- Statistiques descriptives pour le fichier: seller_id ---\n",
      "count            38279\n",
      "unique            2476\n",
      "top       yGbPyLPc8PmT\n",
      "freq               719\n",
      "Name: seller_id, dtype: object\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "--- Statistiques descriptives pour le fichier: price ---\n",
      "count    38279.000000\n",
      "mean       342.499934\n",
      "std        560.285949\n",
      "min          0.850000\n",
      "25%         59.880000\n",
      "50%        136.900000\n",
      "75%        399.200000\n",
      "max       6729.000000\n",
      "Name: price, dtype: float64\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "--- Statistiques descriptives pour le fichier: shipping_charges ---\n",
      "count    38279.000000\n",
      "mean        44.194071\n",
      "std         37.738984\n",
      "min          0.000000\n",
      "25%         19.930000\n",
      "50%         34.600000\n",
      "75%         57.120000\n",
      "max        409.680000\n",
      "Name: shipping_charges, dtype: float64\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "--- Statistiques descriptives pour le fichier: payment_sequential ---\n",
      "count    38279.000000\n",
      "mean         1.096606\n",
      "std          0.742181\n",
      "min          1.000000\n",
      "25%          1.000000\n",
      "50%          1.000000\n",
      "75%          1.000000\n",
      "max         27.000000\n",
      "Name: payment_sequential, dtype: float64\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "--- Statistiques descriptives pour le fichier: payment_type ---\n",
      "count           38279\n",
      "unique              4\n",
      "top       credit_card\n",
      "freq            28265\n",
      "Name: payment_type, dtype: object\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "--- Statistiques descriptives pour le fichier: payment_installments ---\n",
      "count    38279.000000\n",
      "mean         2.982105\n",
      "std          2.836529\n",
      "min          1.000000\n",
      "25%          1.000000\n",
      "50%          2.000000\n",
      "75%          4.000000\n",
      "max         24.000000\n",
      "Name: payment_installments, dtype: float64\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "--- Statistiques descriptives pour le fichier: payment_value ---\n",
      "count    38279.000000\n",
      "mean       267.698041\n",
      "std        366.310037\n",
      "min          0.030000\n",
      "25%         82.175000\n",
      "50%        171.930000\n",
      "75%        309.205000\n",
      "max      13664.080000\n",
      "Name: payment_value, dtype: float64\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "--- Statistiques descriptives pour le fichier: product_category_name ---\n",
      "count     38111\n",
      "unique       66\n",
      "top        toys\n",
      "freq      28697\n",
      "Name: product_category_name, dtype: object\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "--- Statistiques descriptives pour le fichier: product_weight_g ---\n",
      "count    38269.000000\n",
      "mean      2118.472576\n",
      "std       3827.606405\n",
      "min          0.000000\n",
      "25%        300.000000\n",
      "50%        700.000000\n",
      "75%       1800.000000\n",
      "max      30000.000000\n",
      "Name: product_weight_g, dtype: float64\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "--- Statistiques descriptives pour le fichier: product_length_cm ---\n",
      "count    38269.000000\n",
      "mean        30.316366\n",
      "std         16.258049\n",
      "min          7.000000\n",
      "25%         18.000000\n",
      "50%         25.000000\n",
      "75%         38.000000\n",
      "max        105.000000\n",
      "Name: product_length_cm, dtype: float64\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "--- Statistiques descriptives pour le fichier: product_height_cm ---\n",
      "count    38269.000000\n",
      "mean        16.504717\n",
      "std         13.370506\n",
      "min          2.000000\n",
      "25%          8.000000\n",
      "50%         13.000000\n",
      "75%         20.000000\n",
      "max        105.000000\n",
      "Name: product_height_cm, dtype: float64\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "--- Statistiques descriptives pour le fichier: product_width_cm ---\n",
      "count    38269.000000\n",
      "mean        23.154146\n",
      "std         11.869977\n",
      "min          8.000000\n",
      "25%         15.000000\n",
      "50%         20.000000\n",
      "75%         30.000000\n",
      "max        118.000000\n",
      "Name: product_width_cm, dtype: float64\n",
      "\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "# Analyse Statistique \n",
    "\n",
    "# Utiliser la m√©thode describe() pour obtenir des statistiques descriptives sur les colonnes num√©riques\n",
    "for name, df in ts_data.items():\n",
    "    print(f\"\\n--- Statistiques descriptives pour le fichier: {name} ---\")\n",
    "    print(df.describe())  # Afficher les statistiques descriptives\n",
    "    print(\"\\n-----------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Data - Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in Train Data:\n",
      "order_id                    0\n",
      "customer_id                 0\n",
      "order_status                0\n",
      "order_purchase_timestamp    0\n",
      "customer_zip_code_prefix    0\n",
      "customer_city               0\n",
      "customer_state              0\n",
      "product_id                  0\n",
      "seller_id                   0\n",
      "price                       0\n",
      "shipping_charges            0\n",
      "payment_sequential          0\n",
      "payment_type                0\n",
      "payment_installments        0\n",
      "payment_value               0\n",
      "product_category_name       0\n",
      "year                        0\n",
      "month                       0\n",
      "quarter                     0\n",
      "day                         0\n",
      "weekday                     0\n",
      "is_weekend                  0\n",
      "day_of_year                 0\n",
      "Year                        0\n",
      "Month                       0\n",
      "Quarter                     0\n",
      "Day                         0\n",
      "Weekday                     0\n",
      "Is_Weekend                  0\n",
      "Day_Of_Year                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking for missing values\n",
    "tr_data = tr_data[tr_data.order_status == 'delivered']\n",
    "print(\"Missing values in Train Data:\")\n",
    "print(tr_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Data - Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id                    0\n",
      "customer_id                 0\n",
      "order_status                0\n",
      "order_purchase_timestamp    0\n",
      "customer_zip_code_prefix    0\n",
      "customer_city               0\n",
      "customer_state              0\n",
      "product_id                  0\n",
      "seller_id                   0\n",
      "price                       0\n",
      "shipping_charges            0\n",
      "payment_sequential          0\n",
      "payment_type                0\n",
      "payment_installments        0\n",
      "payment_value               0\n",
      "product_category_name       0\n",
      "year                        0\n",
      "month                       0\n",
      "quarter                     0\n",
      "day                         0\n",
      "weekday                     0\n",
      "is_weekend                  0\n",
      "day_of_year                 0\n",
      "Year                        0\n",
      "Month                       0\n",
      "Quarter                     0\n",
      "Day                         0\n",
      "Weekday                     0\n",
      "Is_Weekend                  0\n",
      "Day_Of_Year                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Replace missing values\n",
    "tr_data['product_category_name'] = tr_data['product_category_name'].fillna('Unknown')\n",
    "# Remove irrelevant columns\n",
    "cols_to_drop = [\n",
    "    'order_approved_at',\n",
    "    'order_delivered_timestamp',\n",
    "    'order_estimated_delivery_date',\n",
    "    'product_weight_g',\n",
    "    'product_length_cm',\n",
    "    'product_height_cm',\n",
    "    'product_width_cm'\n",
    "]\n",
    "tr_data.drop(columns=cols_to_drop, inplace=True, errors='ignore')\n",
    "print(tr_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data - Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in Test Data:\n",
      "order_id                      0\n",
      "customer_id                   0\n",
      "order_purchase_timestamp      0\n",
      "order_approved_at             7\n",
      "customer_zip_code_prefix      0\n",
      "customer_city                 0\n",
      "customer_state                0\n",
      "product_id                    0\n",
      "seller_id                     0\n",
      "price                         0\n",
      "shipping_charges              0\n",
      "payment_sequential            0\n",
      "payment_type                  0\n",
      "payment_installments          0\n",
      "payment_value                 0\n",
      "product_category_name       168\n",
      "product_weight_g             10\n",
      "product_length_cm            10\n",
      "product_height_cm            10\n",
      "product_width_cm             10\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking for missing values\n",
    "print(\"Missing values in Test Data:\")\n",
    "print(ts_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data - Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id                    0\n",
      "customer_id                 0\n",
      "order_purchase_timestamp    0\n",
      "customer_zip_code_prefix    0\n",
      "customer_city               0\n",
      "customer_state              0\n",
      "product_id                  0\n",
      "seller_id                   0\n",
      "price                       0\n",
      "shipping_charges            0\n",
      "payment_sequential          0\n",
      "payment_type                0\n",
      "payment_installments        0\n",
      "payment_value               0\n",
      "product_category_name       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Replace missing values\n",
    "ts_data['product_category_name'] = ts_data['product_category_name'].fillna('Unknown')\n",
    "# Remove irrelevant columns\n",
    "cols_to_drop = [\n",
    "    'order_approved_at',\n",
    "    'order_delivered_timestamp',\n",
    "    'product_weight_g',\n",
    "    'product_length_cm',\n",
    "    'product_height_cm',\n",
    "    'product_width_cm'\n",
    "]\n",
    "ts_data.drop(columns=cols_to_drop, inplace=True, errors='ignore')\n",
    "# Convert the relevant columns to datetime \n",
    "ts_data['order_purchase_timestamp'] = pd.to_datetime(ts_data['order_purchase_timestamp'])\n",
    "print(ts_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date to datetime \n",
    "tr_data['order_purchase_timestamp'] = pd.to_datetime(tr_data['order_purchase_timestamp'])\n",
    "tr_data[\"Date\"] = tr_data[\"order_purchase_timestamp\"]\n",
    "\n",
    "# Features temporelles de base\n",
    "tr_data['Year'] = tr_data['Date'].dt.year\n",
    "tr_data['Month'] = tr_data['Date'].dt.month\n",
    "tr_data['Quarter'] = tr_data['Date'].dt.quarter\n",
    "tr_data['Day'] = tr_data['Date'].dt.day\n",
    "\n",
    "# Jour de la semaine (0 = lundi, 6 = dimanche)\n",
    "tr_data['DayOfWeek'] = tr_data['Date'].dt.dayofweek\n",
    "\n",
    "# Jour de l‚Äôann√©e (saisonnalit√© fine)\n",
    "tr_data['DayOfYear'] = tr_data['Date'].dt.dayofyear\n",
    "\n",
    "# Semaine de l‚Äôann√©e (saisonnalit√© fine)\n",
    "tr_data['WeekOfYear'] = tr_data['Date'].dt.isocalendar().week.astype(int)\n",
    "\n",
    "# Week-end (feature binaire)\n",
    "tr_data['IsWeekend'] = tr_data['DayOfWeek'].isin([5, 6]).astype(int)\n",
    "\n",
    "# Function to map each category to a macro category\n",
    "def map_product_category(product_category_name):\n",
    "    # Tech & Electronics \n",
    "    TECH_ELECTRONICS = ['computers_accessories', 'electronics', 'audio', 'consoles_games', 'tables_printing_image', 'computers']\n",
    "    \n",
    "    # Home & Furniture\n",
    "    HOME_FURNITURE = ['garden_tools', 'bed_bath_table', 'furniture_decor', 'office_furniture', \n",
    "                      'housewares', 'home_appliances', 'home_appliances_2', \n",
    "                      'kitchen_dining_laundry_garden_furniture', 'furniture_living_room', \n",
    "                      'furniture_bedroom', 'home_confort', 'home_comfort_2']\n",
    "    \n",
    "    # Fashion & Beauty\n",
    "    FASHION_BEAUTY = ['health_beauty', 'watches_gifts', 'perfumery', 'fashion_bags_accessories', \n",
    "                             'fashion_shoes', 'fashion_sport', 'fashion_childrens_clothes', \n",
    "                             'fashio_female_clothing', 'fashion_male_clothing', 'fashion_underwear_beach']\n",
    "\n",
    "    # Leisure & Entertainment\n",
    "    LEISURE_ENTERTAINMENT = ['toys', 'cool_stuff', 'sports_leisure', 'books_technical', \n",
    "                             'books_general_interest', 'books_imported', 'musical_instruments', 'dvds_blu_ray',\n",
    "                             'cine_photo', 'music']\n",
    "    \n",
    "    # Everyday & Misc\n",
    "    EVERYDAY_MISC = ['stationery', 'market_place', 'small_appliances', \n",
    "                     'party_supplies', 'arts_and_craftmanship', 'pet_shop', 'baby']\n",
    "    \n",
    "    # Others\n",
    "    Others = ['Unknown']   \n",
    "\n",
    "    if product_category_name in TECH_ELECTRONICS:\n",
    "        return 'Tech & Electronics'\n",
    "    elif product_category_name in HOME_FURNITURE:\n",
    "        return 'Home & Furniture'\n",
    "    elif product_category_name in FASHION_BEAUTY:\n",
    "        return 'Fashion & Beauty'\n",
    "    elif product_category_name in LEISURE_ENTERTAINMENT:\n",
    "        return 'Leisure & Entertainment'\n",
    "    elif product_category_name in EVERYDAY_MISC:\n",
    "        return 'Everyday & Misc'\n",
    "    else:\n",
    "        return 'Others'\n",
    "\n",
    "# Apply the function to create a new column with macro categories\n",
    "tr_data['Macro_Category'] = tr_data['product_category_name'].apply(map_product_category)\n",
    "\n",
    "# Define a mapping from states to regions\n",
    "State_To_Region = {\n",
    "    'SP': 'Southeast', 'RJ': 'Southeast', 'MG': 'Southeast', 'ES': 'Southeast',\n",
    "    'RS': 'South', 'PR': 'South', 'SC': 'South',\n",
    "    'BA': 'Northeast', 'PE': 'Northeast', 'CE': 'Northeast', 'PB': 'Northeast', \n",
    "    'AL': 'Northeast', 'RN': 'Northeast', 'SE': 'Northeast', 'MA': 'Northeast', 'PI': 'Northeast',\n",
    "    'GO': 'Central-West', 'DF': 'Central-West', 'MT': 'Central-West', 'MS': 'Central-West',\n",
    "    'PA': 'North', 'AM': 'North', 'RO': 'North', 'TO': 'North',\n",
    "    'AP': 'North', 'AC': 'North', 'RR': 'North'\n",
    "}\n",
    "\n",
    "# Map each state with it's region\n",
    "tr_data['Region'] = tr_data['customer_state'].map(State_To_Region)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Data - Temporal Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>DayOfYear</th>\n",
       "      <th>WeekOfYear</th>\n",
       "      <th>IsWeekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-10-22 18:57:54</td>\n",
       "      <td>2017-10-22</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>295</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-06-20 21:40:31</td>\n",
       "      <td>2018-06-20</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>171</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-02-16 16:19:31</td>\n",
       "      <td>2018-02-16</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-08-18 18:04:29</td>\n",
       "      <td>2018-08-18</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>230</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-12-22 16:44:04</td>\n",
       "      <td>2017-12-22</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>356</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  order_purchase_timestamp        Date  Year  Quarter  Month  Day  DayOfWeek  \\\n",
       "0      2017-10-22 18:57:54  2017-10-22  2017        4     10   22          6   \n",
       "1      2018-06-20 21:40:31  2018-06-20  2018        2      6   20          2   \n",
       "2      2018-02-16 16:19:31  2018-02-16  2018        1      2   16          4   \n",
       "3      2018-08-18 18:04:29  2018-08-18  2018        3      8   18          5   \n",
       "4      2017-12-22 16:44:04  2017-12-22  2017        4     12   22          4   \n",
       "\n",
       "   DayOfYear  WeekOfYear  IsWeekend  \n",
       "0        295          42          1  \n",
       "1        171          25          0  \n",
       "2         47           7          0  \n",
       "3        230          33          1  \n",
       "4        356          51          0  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert date to datetime \n",
    "tr_data['order_purchase_timestamp'] = pd.to_datetime(tr_data['order_purchase_timestamp'])\n",
    "\n",
    "# Features temporelles de base\n",
    "tr_data[\"Date\"] = tr_data[\"order_purchase_timestamp\"].dt.date\n",
    "tr_data['Year'] = tr_data['order_purchase_timestamp'].dt.year\n",
    "tr_data['Month'] = tr_data['order_purchase_timestamp'].dt.month\n",
    "tr_data['Quarter'] = tr_data['order_purchase_timestamp'].dt.quarter\n",
    "tr_data['Day'] = tr_data['order_purchase_timestamp'].dt.day\n",
    "\n",
    "# Jour de la semaine (0 = lundi, 6 = dimanche)\n",
    "tr_data['DayOfWeek'] = tr_data['order_purchase_timestamp'].dt.dayofweek\n",
    "\n",
    "# Jour de l‚Äôann√©e (saisonnalit√© fine)\n",
    "tr_data['DayOfYear'] = tr_data['order_purchase_timestamp'].dt.dayofyear\n",
    "\n",
    "# Semaine de l‚Äôann√©e (saisonnalit√© fine)\n",
    "tr_data['WeekOfYear'] = tr_data['order_purchase_timestamp'].dt.isocalendar().week.astype(int)\n",
    "\n",
    "# Week-end (feature binaire)\n",
    "tr_data['IsWeekend'] = tr_data['DayOfWeek'].isin([5, 6]).astype(int)\n",
    "\n",
    "tr_data[\n",
    "    ['order_purchase_timestamp', 'Date', 'Year', 'Quarter', 'Month', 'Day', 'DayOfWeek', 'DayOfYear', 'WeekOfYear', 'IsWeekend']\n",
    "].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Data - Product Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro_Category\n",
      "Leisure & Entertainment    68480\n",
      "Home & Furniture            6917\n",
      "Fashion & Beauty            4613\n",
      "Others                      3258\n",
      "Tech & Electronics          2515\n",
      "Everyday & Misc             1645\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Function to map each category to a macro category\n",
    "def map_product_category(product_category_name):\n",
    "    # Tech & Electronics \n",
    "    TECH_ELECTRONICS = ['computers_accessories', 'electronics', 'audio', 'consoles_games', 'tables_printing_image', 'computers']\n",
    "    \n",
    "    # Home & Furniture\n",
    "    HOME_FURNITURE = ['garden_tools', 'bed_bath_table', 'furniture_decor', 'office_furniture', \n",
    "                      'housewares', 'home_appliances', 'home_appliances_2', \n",
    "                      'kitchen_dining_laundry_garden_furniture', 'furniture_living_room', \n",
    "                      'furniture_bedroom', 'home_confort', 'home_comfort_2']\n",
    "    \n",
    "    # Fashion & Beauty\n",
    "    FASHION_BEAUTY = ['health_beauty', 'watches_gifts', 'perfumery', 'fashion_bags_accessories', \n",
    "                             'fashion_shoes', 'fashion_sport', 'fashion_childrens_clothes', \n",
    "                             'fashio_female_clothing', 'fashion_male_clothing', 'fashion_underwear_beach']\n",
    "\n",
    "    # Leisure & Entertainment\n",
    "    LEISURE_ENTERTAINMENT = ['toys', 'cool_stuff', 'sports_leisure', 'books_technical', \n",
    "                             'books_general_interest', 'books_imported', 'musical_instruments', 'dvds_blu_ray',\n",
    "                             'cine_photo', 'music']\n",
    "    \n",
    "    # Everyday & Misc\n",
    "    EVERYDAY_MISC = ['stationery', 'market_place', 'small_appliances', \n",
    "                     'party_supplies', 'arts_and_craftmanship', 'pet_shop', 'baby']\n",
    "    \n",
    "    # Others\n",
    "    Others = ['Unknown']   \n",
    "\n",
    "    if product_category_name in TECH_ELECTRONICS:\n",
    "        return 'Tech & Electronics'\n",
    "    elif product_category_name in HOME_FURNITURE:\n",
    "        return 'Home & Furniture'\n",
    "    elif product_category_name in FASHION_BEAUTY:\n",
    "        return 'Fashion & Beauty'\n",
    "    elif product_category_name in LEISURE_ENTERTAINMENT:\n",
    "        return 'Leisure & Entertainment'\n",
    "    elif product_category_name in EVERYDAY_MISC:\n",
    "        return 'Everyday & Misc'\n",
    "    else:\n",
    "        return 'Others'\n",
    "\n",
    "# Apply the function to create a new column with macro categories\n",
    "tr_data['Macro_Category'] = tr_data['product_category_name'].apply(map_product_category)\n",
    "print(tr_data['Macro_Category'].value_counts())\n",
    "#tr_data['macro_category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Data - State to regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region\n",
      "Southeast       60299\n",
      "South           12465\n",
      "Northeast        8051\n",
      "Central-West     5018\n",
      "North            1595\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define a mapping from states to regions\n",
    "State_To_Region = {\n",
    "    'SP': 'Southeast', 'RJ': 'Southeast', 'MG': 'Southeast', 'ES': 'Southeast',\n",
    "    'RS': 'South', 'PR': 'South', 'SC': 'South',\n",
    "    'BA': 'Northeast', 'PE': 'Northeast', 'CE': 'Northeast', 'PB': 'Northeast', \n",
    "    'AL': 'Northeast', 'RN': 'Northeast', 'SE': 'Northeast', 'MA': 'Northeast', 'PI': 'Northeast',\n",
    "    'GO': 'Central-West', 'DF': 'Central-West', 'MT': 'Central-West', 'MS': 'Central-West',\n",
    "    'PA': 'North', 'AM': 'North', 'RO': 'North', 'TO': 'North',\n",
    "    'AP': 'North', 'AC': 'North', 'RR': 'North'\n",
    "}\n",
    "\n",
    "# Map each state with it's region\n",
    "tr_data['Region'] = tr_data['customer_state'].map(State_To_Region)\n",
    "print(tr_data['Region'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Data - Total des ventes dans le temps et par produits & region\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total des ventes (global)\n",
    "tr_data[\"Sales\"] = tr_data[\"price\"]\n",
    "total_sales = tr_data[\"Sales\"].sum()\n",
    "#print(f\"Total des ventes (global) : {total_sales:,.2f}\")\n",
    "\n",
    "# Total des ventes par jour \n",
    "total_sales_per_day = (\n",
    "    tr_data\n",
    "    .groupby(\"Date\", as_index=False)\n",
    "    .agg(total_sales=(\"Sales\", \"sum\"))\n",
    "    .sort_values(\"Date\")\n",
    ")\n",
    "#total_sales_per_day.head()\n",
    "\n",
    "# Total des ventes par mois\n",
    "total_sales_per_month = (\n",
    "    tr_data.groupby([\"Year\", \"Month\"])[\"Sales\"]\n",
    "    .sum()\n",
    "    .reset_index(name=\"total_sales\")\n",
    ")\n",
    "\n",
    "# Total des ventes par trimestre\n",
    "total_sales_per_quarter = (\n",
    "    tr_data.groupby([\"Year\", \"Quarter\"])[\"Sales\"]\n",
    "    .sum()\n",
    "    .reset_index(name=\"total_sales\")\n",
    ")\n",
    "\n",
    "# Total des ventes par ann√©e\n",
    "total_sales_per_year = (\n",
    "    tr_data.groupby(\"Year\")[\"Sales\"]\n",
    "    .sum()\n",
    "    .reset_index(name=\"total_sales\")\n",
    ")\n",
    "\n",
    "# Total des ventes par produits\n",
    "total_sales_per_product = (\n",
    "    tr_data\n",
    "    .groupby(\"Macro_Category\", as_index=False)\n",
    "    .agg(total_sales=(\"sales\", \"sum\"))\n",
    "    .sort_values(\"total_sales\", ascending=False)\n",
    ")\n",
    "\n",
    "#total_sales_per_product.head()\n",
    "\n",
    "# Total des ventes par region\n",
    "total_sales_per_region = (\n",
    "    tr_data\n",
    "    .groupby(\"Region\", as_index=False)\n",
    "    .agg(total_sales=(\"sales\", \"sum\"))\n",
    "    .sort_values(\"total_sales\", ascending=False)\n",
    ")\n",
    "\n",
    "#total_sales_per_region.head()\n",
    "\n",
    "# Total des ventes par produit √ó r√©gion\n",
    "total_sales_product_region = (\n",
    "    tr_data\n",
    "    .groupby([\"Macro_Category\", \"Region\"], as_index=False)\n",
    "    .agg(total_sales=(\"sales\", \"sum\"))\n",
    "    .sort_values(\"total_sales\", ascending=False)\n",
    ")\n",
    "\n",
    "#total_sales_product_region.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Data - Ventes moyennes dans le temps et par produits & region\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ventes moyennes par jour\n",
    "avg_daily_sales = tr_data.groupby(\"Date\")[\"sales\"].sum().mean()\n",
    "#print(f\"Vente moyenne journali√®re : {avg_daily_sales:,.2f}\")\n",
    "\n",
    "# Ventes moyennes par mois\n",
    "avg_monthly_sales = tr_data.groupby([\"Year\", \"Month\"])[\"sales\"].sum().mean()\n",
    "\n",
    "# Ventes moyennes par trimestre\n",
    "avg_quarterly_sales = tr_data.groupby([\"Year\", \"Quarter\"])[\"sales\"].sum().mean()\n",
    "\n",
    "# Ventes moyennes par ann√©e\n",
    "avg_yearly_sales = tr_data.groupby(\"Year\")[\"sales\"].sum().mean()\n",
    "\n",
    "# Ventes moyennes par produit\n",
    "avg_sales_per_product = (\n",
    "    tr_data\n",
    "    .groupby(\"Macro_Category\")[\"Sales\"].mean()\n",
    "    .reset_index(name=\"avg_sales\")\n",
    ")\n",
    "\n",
    "# Ventes moyennes par region\n",
    "avg_sales_per_region = (\n",
    "    tr_data\n",
    "    .groupby(\"Region\")[\"Sales\"].mean()\n",
    "    .reset_index(name=\"avg_sales\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Data - Total des commandes dans le temps et par produits & region\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total de commandes\n",
    "total_orders = tr_data[\"order_id\"].nunique()\n",
    "\n",
    "# Total de commandes par jour\n",
    "total_orders_per_day = (\n",
    "    tr_data.groupby(\"Date\")[\"order_id\"]\n",
    "    .nunique()\n",
    "    .reset_index(name=\"nb_commandes\")\n",
    ")\n",
    "\n",
    "# Total de commandes par mois\n",
    "total_orders_per_month = (\n",
    "    tr_data.groupby([\"Year\", \"Month\"])[\"order_id\"]\n",
    "    .nunique()\n",
    "    .reset_index(name=\"nb_commandes\")\n",
    ")\n",
    "\n",
    "# Total de commandes par trimestre\n",
    "total_orders_per_quarter = (\n",
    "    tr_data.groupby([\"Year\", \"Quarter\"])[\"order_id\"]\n",
    "    .nunique()\n",
    "    .reset_index(name=\"nb_commandes\")\n",
    ")\n",
    "# Total de commandes par ann√©e\n",
    "total_orders_per_year = (\n",
    "    tr_data.groupby(\"Year\")[\"order_id\"]\n",
    "    .nunique()\n",
    "    .reset_index(name=\"nb_commandes\")\n",
    ")\n",
    "\n",
    "# Total de commandes par produits\n",
    "total_orders_per_product = (\n",
    "    tr_data.groupby(\"Macro_Category\")[\"order_id\"]\n",
    "    .nunique()\n",
    "    .reset_index(name=\"nb_commandes\")\n",
    ")\n",
    "\n",
    "# Total de commandes par region\n",
    "total_orders_per_region = (\n",
    "    tr_data.groupby(\"Region\")[\"order_id\"]\n",
    "    .nunique()\n",
    "    .reset_index(name=\"nb_commandes\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Train Data - Nombre de clients dans le temps et par produits & region\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Clients \n",
    "total_clients = tr_data[\"customer_id\"].nunique()\n",
    "\n",
    "# Clients actifs par jour\n",
    "clients_per_day = (\n",
    "    tr_data.groupby(\"Date\")[\"customer_id\"]\n",
    "    .nunique()\n",
    "    .reset_index(name=\"clients_actifs_jour\")\n",
    ")\n",
    "\n",
    "# Clients actifs par mois\n",
    "clients_per_month = (\n",
    "    tr_data.groupby([\"Year\", \"Month\"])[\"customer_id\"]\n",
    "    .nunique()\n",
    "    .reset_index(name=\"clients_actifs_mois\")\n",
    ")\n",
    "\n",
    "# Clients actifs par trimestre\n",
    "clients_per_quarter = (\n",
    "    tr_data.groupby([\"Year\", \"Quarter\"])[\"customer_id\"]\n",
    "    .nunique()\n",
    "    .reset_index(name=\"clients_actifs_trimestre\")\n",
    ")\n",
    "\n",
    "# Clients actifs par ann√©e \n",
    "clients_per_year = (\n",
    "    tr_data.groupby(\"Year\")[\"customer_id\"]\n",
    "    .nunique()\n",
    "    .reset_index(name=\"clients_actifs_annee\")\n",
    ")\n",
    "\n",
    "# Client actifs par produit\n",
    "clients_per_product = (\n",
    "    tr_data.groupby([\"Macro_Category\"])[\"customer_id\"]\n",
    "    .nunique()\n",
    "    .reset_index(name=\"nb_clients\")\n",
    ")\n",
    "\n",
    "# Client actifs par region\n",
    "clients_per_region = (\n",
    "    tr_data.groupby([\"Region\"])[\"customer_id\"]\n",
    "    .nunique()\n",
    "    .reset_index(name=\"nb_clients\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Train Data - Nombre moyens de clients dans le temps et par produits & region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre de clients moyens par jour\n",
    "avg_daily_cust = (\n",
    "    tr_data.groupby(\"Date\")[\"customer_id\"]\n",
    "    .nunique()\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "# Nombre de clients moyens par mois\n",
    "avg_monthly_cust = (\n",
    "    tr_data.groupby([\"Year\", \"Month\"])[\"customer_id\"]\n",
    "    .nunique()\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "# Nombre de clients moyens par trimestre\n",
    "avg_quarterly_cust = (\n",
    "    tr_data.groupby([\"Year\", \"Quarter\"])[\"customer_id\"]\n",
    "    .nunique()\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "# Nombre de clients moyens par ann√©e\n",
    "avg_yearly_cust = (\n",
    "    tr_data.groupby(\"Year\")[\"customer_id\"]\n",
    "    .nunique()\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "# Nombre de clients moyens par produits\n",
    "avg_product_cust = (\n",
    "    tr_data.groupby(\"Macro_Category\")[\"customer_id\"]\n",
    "    .nunique()\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "# Nombre de clients moyens par region\n",
    "avg_region_cust = (\n",
    "    tr_data.groupby(\"Region\")[\"customer_id\"]\n",
    "    .nunique()\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "# Nombre de produits vendus par jour\n",
    "nb_produits_vendus_jour = (\n",
    "    tr_data.groupby(\"Date\")[\"product_id\"]\n",
    "    .count()\n",
    "    .reset_index(name=\"nb_produits_vendus\")\n",
    ")\n",
    "\n",
    "# Nombre de commandes par client\n",
    "commandes_par_client = (\n",
    "    tr_data.groupby(\"customer_id\")[\"order_id\"]\n",
    "    .nunique()\n",
    "    .reset_index(name=\"nb_commandes\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Train Data - Analyse des ventes par types de paiement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_sales</th>\n",
       "      <th>avg_sales</th>\n",
       "      <th>nb_orders</th>\n",
       "      <th>nb_customers</th>\n",
       "      <th>sales_share_%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>payment_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>credit_card</th>\n",
       "      <td>21748493.76</td>\n",
       "      <td>337.526092</td>\n",
       "      <td>64435</td>\n",
       "      <td>64435</td>\n",
       "      <td>72.675423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wallet</th>\n",
       "      <td>6086051.25</td>\n",
       "      <td>359.292240</td>\n",
       "      <td>16939</td>\n",
       "      <td>16939</td>\n",
       "      <td>20.337333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>voucher</th>\n",
       "      <td>1676522.16</td>\n",
       "      <td>350.004626</td>\n",
       "      <td>4790</td>\n",
       "      <td>4790</td>\n",
       "      <td>5.602317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>debit_card</th>\n",
       "      <td>414446.46</td>\n",
       "      <td>327.884858</td>\n",
       "      <td>1264</td>\n",
       "      <td>1264</td>\n",
       "      <td>1.384927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              total_sales   avg_sales  nb_orders  nb_customers  sales_share_%\n",
       "payment_type                                                                 \n",
       "credit_card   21748493.76  337.526092      64435         64435      72.675423\n",
       "wallet         6086051.25  359.292240      16939         16939      20.337333\n",
       "voucher        1676522.16  350.004626       4790          4790       5.602317\n",
       "debit_card      414446.46  327.884858       1264          1264       1.384927"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total des ventes par type de paiement\n",
    "sales_by_payment = (\n",
    "    tr_data.groupby('payment_type')\n",
    "    .agg(\n",
    "        total_sales=('Sales', 'sum'),\n",
    "        avg_sales=('Sales', 'mean'),\n",
    "        nb_orders=('order_id', 'nunique'),\n",
    "        nb_customers=('customer_id', 'nunique')\n",
    "    )\n",
    "    .sort_values('total_sales', ascending=False)\n",
    ")\n",
    "\n",
    "# Part des ventes par type de paiement (%)\n",
    "sales_by_payment['sales_share_%'] = (\n",
    "    sales_by_payment['total_sales'] /\n",
    "    sales_by_payment['total_sales'].sum() * 100\n",
    ")\n",
    "\n",
    "sales_by_payment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Train Data - Lags & Rolling Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Region</th>\n",
       "      <th>daily_sales</th>\n",
       "      <th>sales_lag_1</th>\n",
       "      <th>sales_lag_7</th>\n",
       "      <th>sales_lag_14</th>\n",
       "      <th>sales_lag_30</th>\n",
       "      <th>rolling_mean_7</th>\n",
       "      <th>rolling_mean_14</th>\n",
       "      <th>rolling_mean_30</th>\n",
       "      <th>rolling_std_7</th>\n",
       "      <th>rolling_std_14</th>\n",
       "      <th>rolling_std_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>2017-01-25 18:22:36</td>\n",
       "      <td>Central-West</td>\n",
       "      <td>30.94</td>\n",
       "      <td>164.98</td>\n",
       "      <td>33.41</td>\n",
       "      <td>468.90</td>\n",
       "      <td>12.26</td>\n",
       "      <td>69.992857</td>\n",
       "      <td>158.746429</td>\n",
       "      <td>467.097667</td>\n",
       "      <td>51.412065</td>\n",
       "      <td>260.817691</td>\n",
       "      <td>793.108627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>2017-01-26 00:16:29</td>\n",
       "      <td>Central-West</td>\n",
       "      <td>188.80</td>\n",
       "      <td>30.94</td>\n",
       "      <td>26.20</td>\n",
       "      <td>1036.36</td>\n",
       "      <td>329.96</td>\n",
       "      <td>93.221429</td>\n",
       "      <td>98.206429</td>\n",
       "      <td>462.392333</td>\n",
       "      <td>63.612839</td>\n",
       "      <td>70.012436</td>\n",
       "      <td>794.368024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>2017-01-26 10:00:37</td>\n",
       "      <td>Central-West</td>\n",
       "      <td>181.56</td>\n",
       "      <td>188.80</td>\n",
       "      <td>68.10</td>\n",
       "      <td>81.50</td>\n",
       "      <td>394.80</td>\n",
       "      <td>109.430000</td>\n",
       "      <td>105.353571</td>\n",
       "      <td>455.284333</td>\n",
       "      <td>70.253294</td>\n",
       "      <td>73.210028</td>\n",
       "      <td>795.946163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>2017-01-26 13:43:07</td>\n",
       "      <td>Central-West</td>\n",
       "      <td>26.85</td>\n",
       "      <td>181.56</td>\n",
       "      <td>89.10</td>\n",
       "      <td>250.92</td>\n",
       "      <td>61.70</td>\n",
       "      <td>100.537143</td>\n",
       "      <td>89.348571</td>\n",
       "      <td>454.122667</td>\n",
       "      <td>76.882724</td>\n",
       "      <td>62.673262</td>\n",
       "      <td>796.565589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>2017-01-26 13:51:54</td>\n",
       "      <td>Central-West</td>\n",
       "      <td>226.37</td>\n",
       "      <td>26.85</td>\n",
       "      <td>19.30</td>\n",
       "      <td>172.13</td>\n",
       "      <td>2899.00</td>\n",
       "      <td>130.118571</td>\n",
       "      <td>93.222857</td>\n",
       "      <td>365.035000</td>\n",
       "      <td>80.181801</td>\n",
       "      <td>69.489987</td>\n",
       "      <td>649.597571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Date        Region  daily_sales  sales_lag_1  sales_lag_7  \\\n",
       "533 2017-01-25 18:22:36  Central-West        30.94       164.98        33.41   \n",
       "545 2017-01-26 00:16:29  Central-West       188.80        30.94        26.20   \n",
       "550 2017-01-26 10:00:37  Central-West       181.56       188.80        68.10   \n",
       "570 2017-01-26 13:43:07  Central-West        26.85       181.56        89.10   \n",
       "571 2017-01-26 13:51:54  Central-West       226.37        26.85        19.30   \n",
       "\n",
       "     sales_lag_14  sales_lag_30  rolling_mean_7  rolling_mean_14  \\\n",
       "533        468.90         12.26       69.992857       158.746429   \n",
       "545       1036.36        329.96       93.221429        98.206429   \n",
       "550         81.50        394.80      109.430000       105.353571   \n",
       "570        250.92         61.70      100.537143        89.348571   \n",
       "571        172.13       2899.00      130.118571        93.222857   \n",
       "\n",
       "     rolling_mean_30  rolling_std_7  rolling_std_14  rolling_std_30  \n",
       "533       467.097667      51.412065      260.817691      793.108627  \n",
       "545       462.392333      63.612839       70.012436      794.368024  \n",
       "550       455.284333      70.253294       73.210028      795.946163  \n",
       "570       454.122667      76.882724       62.673262      796.565589  \n",
       "571       365.035000      80.181801       69.489987      649.597571  "
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agr√©gation ventes journali√®res par r√©gion\n",
    "sales_region_day = (\n",
    "    tr_data.groupby(['Date', 'Region'])\n",
    "    .agg(daily_sales=('Sales', 'sum'))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Trier correctement\n",
    "sales_region_day = sales_region_day.sort_values(\n",
    "    ['Region', 'Date']\n",
    ")\n",
    "\n",
    "# Cr√©ation des lags\n",
    "lags = [1, 7, 14, 30]\n",
    "\n",
    "for lag in lags:\n",
    "    sales_region_day[f'sales_lag_{lag}'] = (\n",
    "        sales_region_day.groupby('Region')['daily_sales']\n",
    "        .shift(lag)\n",
    "    )\n",
    "\n",
    "# Supprimer les lignes avec des valeurs manquantes (dus aux lags)\n",
    "#sales_region_day.dropna(inplace=True)\n",
    "\n",
    "# Cr√©ation des rolling means (moyennes glissantes)\n",
    "windows = [7, 14, 30]\n",
    "\n",
    "for window in windows:\n",
    "    sales_region_day[f'rolling_mean_{window}'] = (\n",
    "        sales_region_day.groupby('Region')['daily_sales']\n",
    "        .rolling(window=window)\n",
    "        .mean()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "# Cr√©ation des rolling std (volatilit√©)\n",
    "for window in windows:\n",
    "    sales_region_day[f'rolling_std_{window}'] = (\n",
    "        sales_region_day.groupby('Region')['daily_sales']\n",
    "        .rolling(window=window)\n",
    "        .std()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "# Supprimer les lignes avec des valeurs manquantes (dus aux rolling calculations)\n",
    "sales_region_day.dropna(inplace=True)\n",
    "sales_region_day.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(59818) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting joblib\n",
      "  Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Downloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "Installing collected packages: joblib\n",
      "Successfully installed joblib-1.5.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install joblib\n",
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(60567) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dotenv\n",
      "  Downloading dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\n",
      "Collecting python-dotenv (from dotenv)\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Downloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
      "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Installing collected packages: python-dotenv, dotenv\n",
      "Successfully installed dotenv-0.9.9 python-dotenv-1.2.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "TRAIN_DIR = os.getenv(\"TRAIN_DIR\")\n",
    "MODELS_DIR = os.getenv(\"MODELS_DIR\")\n",
    "RANDOM_STATE = int(os.getenv(\"RANDOM_STATE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/python3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: /usr/local/bin/python3\n",
      "Python version: 3.13.1 (v3.13.1:06714517797, Dec  3 2024, 14:00:22) [Clang 15.0.0 (clang-1500.3.9.4)]\n",
      "site-packages: ['/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys, site\n",
    "print(\"Python executable:\", sys.executable)\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"site-packages:\", site.getsitepackages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.11.14)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "\n",
    "# =========================\n",
    "# CONFIG √Ä ADAPTER SI BESOIN\n",
    "# =========================\n",
    "DF = tr_data\n",
    "DATE_COL = \"Date\"   # ou \"order_purchase_timestamp\"\n",
    "TARGET_COL = \"daily_sales\"         # ta cible\n",
    "DROP_COLS = []                     # ex: [\"order_id\"] si tu veux\n",
    "\n",
    "MODELS_DIR = \"./models\"\n",
    "ARTEFACTS_DIR = \"./artefacts\"\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "os.makedirs(ARTEFACTS_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    y_true = np.array(y_true, dtype=float)\n",
    "    y_pred = np.array(y_pred, dtype=float)\n",
    "    mask = y_true != 0\n",
    "    return float(np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100) if mask.any() else np.nan\n",
    "\n",
    "def time_split(df, date_col, test_size=0.2):\n",
    "    df = df.sort_values(date_col).reset_index(drop=True)\n",
    "    split_idx = int(len(df) * (1 - test_size))\n",
    "    return df.iloc[:split_idx].copy(), df.iloc[split_idx:].copy()\n",
    "\n",
    "def save_json(path, obj):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "def ensure_datetime(df, col):\n",
    "    df = df.copy()\n",
    "    df[col] = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "def benchmark_and_save_5models(df, date_col, target_col, models_dir, artefacts_dir, test_size=0.2):\n",
    "    run_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_dir = os.path.join(artefacts_dir, f\"run_{run_id}\")\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    preds_dir = os.path.join(run_dir, \"predictions\")\n",
    "    os.makedirs(preds_dir, exist_ok=True)\n",
    "\n",
    "    # ---- Clean minimal ----\n",
    "    df = df.copy()\n",
    "    df = df.drop(columns=DROP_COLS, errors=\"ignore\")\n",
    "    df = ensure_datetime(df, date_col)\n",
    "    df = df.dropna(subset=[date_col, target_col]).sort_values(date_col)\n",
    "\n",
    "    # Garde features num√©riques uniquement (pour ML + SARIMAX exog)\n",
    "    feature_cols = [c for c in df.columns if c not in {date_col, target_col}]\n",
    "    X_all = df[feature_cols].select_dtypes(include=[np.number]).copy()\n",
    "    df_final = pd.concat([df[[date_col, target_col]].reset_index(drop=True), X_all.reset_index(drop=True)], axis=1)\n",
    "    df_final = df_final.dropna().reset_index(drop=True)\n",
    "\n",
    "    feature_cols = list(X_all.columns)\n",
    "\n",
    "    train_df, test_df = time_split(df_final, date_col, test_size=test_size)\n",
    "\n",
    "    X_train = train_df[feature_cols]\n",
    "    y_train = train_df[target_col].astype(float)\n",
    "\n",
    "    X_test = test_df[feature_cols]\n",
    "    y_test = test_df[target_col].astype(float)\n",
    "\n",
    "    # Pour les mod√®les purement time-series (sans exog)\n",
    "    y_train_ts = y_train.values\n",
    "    y_test_ts = y_test.values\n",
    "\n",
    "    # ---- Save run config ----\n",
    "    save_json(os.path.join(run_dir, \"run_config.json\"), {\n",
    "        \"run_id\": run_id,\n",
    "        \"date_col\": date_col,\n",
    "        \"target_col\": target_col,\n",
    "        \"test_size\": test_size,\n",
    "        \"n_rows\": int(len(df_final)),\n",
    "        \"n_train\": int(len(train_df)),\n",
    "        \"n_test\": int(len(test_df)),\n",
    "        \"features_numeric\": feature_cols\n",
    "    })\n",
    "    save_json(os.path.join(run_dir, \"split_info.json\"), {\n",
    "        \"train_start\": str(train_df[date_col].min()),\n",
    "        \"train_end\": str(train_df[date_col].max()),\n",
    "        \"test_start\": str(test_df[date_col].min()),\n",
    "        \"test_end\": str(test_df[date_col].max()),\n",
    "    })\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # =========================\n",
    "    # 1) Linear Regression\n",
    "    # =========================\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    pred_lr = lr.predict(X_test)\n",
    "\n",
    "    lr_path = os.path.join(models_dir, f\"LinearRegression__{run_id}.joblib\")\n",
    "    joblib.dump(lr, lr_path)\n",
    "\n",
    "    results.append({\n",
    "        \"run_id\": run_id, \"model\": \"LinearRegression\",\n",
    "        \"MAE\": float(mean_absolute_error(y_test, pred_lr)),\n",
    "        \"RMSE\": rmse(y_test, pred_lr),\n",
    "        \"MAPE\": mape(y_test, pred_lr),\n",
    "        \"model_path\": lr_path\n",
    "    })\n",
    "    pd.DataFrame({date_col: test_df[date_col], \"y_true\": y_test, \"y_pred\": pred_lr}).to_csv(\n",
    "        os.path.join(preds_dir, f\"LinearRegression__preds.csv\"), index=False\n",
    "    )\n",
    "\n",
    "    # =========================\n",
    "    # 2) Random Forest\n",
    "    # =========================\n",
    "    rf = RandomForestRegressor(n_estimators=500, random_state=42, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "    pred_rf = rf.predict(X_test)\n",
    "\n",
    "    rf_path = os.path.join(models_dir, f\"RandomForest__{run_id}.joblib\")\n",
    "    joblib.dump(rf, rf_path)\n",
    "\n",
    "    results.append({\n",
    "        \"run_id\": run_id, \"model\": \"RandomForest\",\n",
    "        \"MAE\": float(mean_absolute_error(y_test, pred_rf)),\n",
    "        \"RMSE\": rmse(y_test, pred_rf),\n",
    "        \"MAPE\": mape(y_test, pred_rf),\n",
    "        \"model_path\": rf_path\n",
    "    })\n",
    "    pd.DataFrame({date_col: test_df[date_col], \"y_true\": y_test, \"y_pred\": pred_rf}).to_csv(\n",
    "        os.path.join(preds_dir, f\"RandomForest__preds.csv\"), index=False\n",
    "    )\n",
    "\n",
    "    # =========================\n",
    "    # 3) XGBoost\n",
    "    # =========================\n",
    "    xgb = XGBRegressor(\n",
    "        n_estimators=800,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=8,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    xgb.fit(X_train, y_train)\n",
    "    pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "    xgb_path = os.path.join(models_dir, f\"XGBoost__{run_id}.joblib\")\n",
    "    joblib.dump(xgb, xgb_path)\n",
    "\n",
    "    results.append({\n",
    "        \"run_id\": run_id, \"model\": \"XGBoost\",\n",
    "        \"MAE\": float(mean_absolute_error(y_test, pred_xgb)),\n",
    "        \"RMSE\": rmse(y_test, pred_xgb),\n",
    "        \"MAPE\": mape(y_test, pred_xgb),\n",
    "        \"model_path\": xgb_path\n",
    "    })\n",
    "    pd.DataFrame({date_col: test_df[date_col], \"y_true\": y_test, \"y_pred\": pred_xgb}).to_csv(\n",
    "        os.path.join(preds_dir, f\"XGBoost__preds.csv\"), index=False\n",
    "    )\n",
    "\n",
    "    # =========================\n",
    "    # 4) SARIMAX (avec exog)\n",
    "    # =========================\n",
    "    # (p,d,q)(P,D,Q,s) : √† tuner plus tard. Ici un baseline.\n",
    "    sarimax = SARIMAX(\n",
    "        endog=y_train_ts,\n",
    "        exog=X_train.values if X_train.shape[1] > 0 else None,\n",
    "        order=(1, 1, 1),\n",
    "        seasonal_order=(0, 0, 0, 0),\n",
    "        enforce_stationarity=False,\n",
    "        enforce_invertibility=False\n",
    "    ).fit(disp=False)\n",
    "\n",
    "    pred_sarimax = sarimax.forecast(\n",
    "        steps=len(y_test_ts),\n",
    "        exog=X_test.values if X_test.shape[1] > 0 else None\n",
    "    )\n",
    "\n",
    "    sarimax_path = os.path.join(models_dir, f\"SARIMAX__{run_id}.pkl\")\n",
    "    sarimax.save(sarimax_path)\n",
    "\n",
    "    results.append({\n",
    "        \"run_id\": run_id, \"model\": \"SARIMAX\",\n",
    "        \"MAE\": float(mean_absolute_error(y_test_ts, pred_sarimax)),\n",
    "        \"RMSE\": rmse(y_test_ts, pred_sarimax),\n",
    "        \"MAPE\": mape(y_test_ts, pred_sarimax),\n",
    "        \"model_path\": sarimax_path\n",
    "    })\n",
    "    pd.DataFrame({date_col: test_df[date_col], \"y_true\": y_test_ts, \"y_pred\": pred_sarimax}).to_csv(\n",
    "        os.path.join(preds_dir, f\"SARIMAX__preds.csv\"), index=False\n",
    "    )\n",
    "\n",
    "    # =========================\n",
    "    # 5) Holt-Winters (ExponentialSmoothing)\n",
    "    # =========================\n",
    "    # Baseline: trend additive, sans saisonnalit√© (tu peux mettre seasonal si tu as une fr√©quence stable)\n",
    "    hw = ExponentialSmoothing(\n",
    "        y_train_ts,\n",
    "        trend=\"add\",\n",
    "        seasonal=None\n",
    "    ).fit()\n",
    "\n",
    "    pred_hw = hw.forecast(len(y_test_ts))\n",
    "\n",
    "    hw_path = os.path.join(models_dir, f\"HoltWinters__{run_id}.pkl\")\n",
    "    hw.save(hw_path)\n",
    "\n",
    "    results.append({\n",
    "        \"run_id\": run_id, \"model\": \"HoltWinters\",\n",
    "        \"MAE\": float(mean_absolute_error(y_test_ts, pred_hw)),\n",
    "        \"RMSE\": rmse(y_test_ts, pred_hw),\n",
    "        \"MAPE\": mape(y_test_ts, pred_hw),\n",
    "        \"model_path\": hw_path\n",
    "    })\n",
    "    pd.DataFrame({date_col: test_df[date_col], \"y_true\": y_test_ts, \"y_pred\": pred_hw}).to_csv(\n",
    "        os.path.join(preds_dir, f\"HoltWinters__preds.csv\"), index=False\n",
    "    )\n",
    "\n",
    "    metrics_df = pd.DataFrame(results).sort_values(\"RMSE\").reset_index(drop=True)\n",
    "    metrics_df.to_csv(os.path.join(run_dir, \"metrics.csv\"), index=False)\n",
    "    save_json(os.path.join(run_dir, \"metrics.json\"), results)\n",
    "\n",
    "    return metrics_df, run_dir\n",
    "\n",
    "\n",
    "# =========================\n",
    "# RUN\n",
    "# =========================\n",
    "metrics_df, artefacts_path = benchmark_and_save_5models(\n",
    "    df=DF,\n",
    "    date_col=DATE_COL,\n",
    "    target_col=TARGET_COL,\n",
    "    models_dir=MODELS_DIR,\n",
    "    artefacts_dir=ARTEFACTS_DIR,\n",
    "    test_size=0.2\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Artefacts:\", artefacts_path)\n",
    "print(\"‚úÖ Mod√®les sauvegard√©s dans:\", MODELS_DIR)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87428"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>clients_actifs_annee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>40082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>47089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  clients_actifs_annee\n",
       "0  2016                   257\n",
       "1  2017                 40082\n",
       "2  2018                 47089"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients_per_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>clients_actifs_mois</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>1467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>2316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>2042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>3301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>2884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>3699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>3942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>3864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>4166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>6694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>4883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>6326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>5957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>6352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>6096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>6069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>5471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>5335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>5483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year  month  clients_actifs_mois\n",
       "0   2016     10                  256\n",
       "1   2016     12                    1\n",
       "2   2017      1                  824\n",
       "3   2017      2                 1467\n",
       "4   2017      3                 2316\n",
       "5   2017      4                 2042\n",
       "6   2017      5                 3301\n",
       "7   2017      6                 2884\n",
       "8   2017      7                 3699\n",
       "9   2017      8                 3942\n",
       "10  2017      9                 3864\n",
       "11  2017     10                 4166\n",
       "12  2017     11                 6694\n",
       "13  2017     12                 4883\n",
       "14  2018      1                 6326\n",
       "15  2018      2                 5957\n",
       "16  2018      3                 6352\n",
       "17  2018      4                 6096\n",
       "18  2018      5                 6069\n",
       "19  2018      6                 5471\n",
       "20  2018      7                 5335\n",
       "21  2018      8                 5483"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients_per_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>total_sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-03</td>\n",
       "      <td>4292.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-10-04</td>\n",
       "      <td>12079.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-10-05</td>\n",
       "      <td>9666.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-10-06</td>\n",
       "      <td>15266.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-10-07</td>\n",
       "      <td>12994.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  total_sales\n",
       "0  2016-10-03      4292.73\n",
       "1  2016-10-04     12079.74\n",
       "2  2016-10-05      9666.65\n",
       "3  2016-10-06     15266.24\n",
       "4  2016-10-07     12994.68"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_sales_per_day.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
